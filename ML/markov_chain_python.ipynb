{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "markov-chain-python.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/u6yuvi/DL-POC/blob/main/ML/markov_chain_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcnTKFX5jDzg"
      },
      "source": [
        "# Build a Sentence Generator Markov Chain in 20 lines of Python\n",
        "\n",
        "> A bot who can write a long letter with ease, cannot write ill.\n",
        "\n",
        "<small><em>&mdash;Jane Austen, Pride and Prejudice</em></small>\n",
        "\n",
        "This post walks you through how to write a [Markov\n",
        "Chain](https://en.wikipedia.org/wiki/Markov_chain) from scratch with Python in\n",
        "order to generate completely new sentences that resemble English.\n",
        "\n",
        "The text we'll be using to build the Markov Chain is [Pride and Prejudice by\n",
        "Jane Austen](https://www.goodreads.com/book/show/1885.Pride_and_Prejudice). You\n",
        "can follow along here or grab a runnable notebook version of this post on\n",
        "[Colab](https://colab.research.google.com/drive/14KjFfYEVhFl3nyuGZtFi1vnv5hN88Qn2).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asDPTXnb4U1q"
      },
      "source": [
        "# Setup\n",
        "\n",
        "First download the full text of Pride and Prejudice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6xNgeAoiK3L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "42c5bf4a-6b06-48ab-e0b6-7318275c88a2"
      },
      "source": [
        "# Download Pride and Prejudice and cut off header.\n",
        "!curl https://www.gutenberg.org/files/1342/1342-0.txt | tail -n+32 > /content/pride-and-prejudice.txt\n",
        "  \n",
        "# Preview file.\n",
        "!head -n 10 /content/pride-and-prejudice.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  780k  100  780k    0     0   553k      0  0:00:01  0:00:01 --:--:--  553k\n",
            "cover\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "      Pride and Prejudice\n",
            "\n",
            "      By Jane Austen\n",
            "\n",
            "        CONTENTS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMrTAA-z4Yt2"
      },
      "source": [
        "Add some necessary imports."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgz7jsnPjkK9"
      },
      "source": [
        "import collections\n",
        "import random\n",
        "import re\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOJSGRwg4ih9"
      },
      "source": [
        "# Building the Markov Chain\n",
        "\n",
        "Read the file into a string and split the words into a list. Then, we can use\n",
        "Python's handy [defaultdict](https://docs.python.org/3/library/collections.html#collections.defaultdict)\n",
        "to create the Markov Chain.\n",
        "\n",
        "To build the chain, take every word in the text and insert it into the\n",
        "dictionary where the key is the previous word, incrementing the counter for\n",
        "that word in the inner dictionary each time. This generates a dictionary where\n",
        "each key points to all the words that have ever followed it, along with the\n",
        "number of instances.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "offgEnAqjDDy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "ac82fec5-fdd1-4a46-e8e8-ec51365ec52b"
      },
      "source": [
        "# Read text from file and tokenize.\n",
        "path = '/content/pride-and-prejudice.txt'\n",
        "with open(path) as f:\n",
        "  text = f.read()\n",
        "tokenized_text = [\n",
        "    word\n",
        "    for word in re.split('\\W+', text)\n",
        "    if word != ''\n",
        "]\n",
        " \n",
        "# Create graph.\n",
        "markov_graph = collections.defaultdict(lambda: collections.Counter())\n",
        "\n",
        "last_word = tokenized_text[0].lower()\n",
        "for word in tokenized_text[1:]:\n",
        "  word = word.lower()\n",
        "  markov_graph[last_word].update([word])\n",
        "  last_word = word\n",
        "\n",
        "# Preview graph.\n",
        "limit = 3\n",
        "for first_word in ('the', 'by', 'who'):\n",
        "  next_words = list(markov_graph[first_word].keys())[:limit]\n",
        "  for next_word in next_words:\n",
        "    print(first_word, next_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the feelings\n",
            "the minds\n",
            "the surrounding\n",
            "by jane\n",
            "by a\n",
            "by the\n",
            "who has\n",
            "who waited\n",
            "who came\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD5zFBeS4m3S"
      },
      "source": [
        "# Generating Sentences\n",
        "\n",
        "Now for the fun part. Define a function to help us walk the chain. It starts at\n",
        "a random word and of the possible choices for the next word, it takes a\n",
        "weighted random choice using\n",
        "[np.random.choice](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.choice.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRhDtYPRnZ4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "931dcdf6-49d0-482f-bd27-f9aa66cca3e6"
      },
      "source": [
        "def walk_graph(graph, distance=5, start_node=None):\n",
        "  \"\"\"Returns a list of words from a randomly weighted walk.\"\"\"\n",
        "  if distance <= 0:\n",
        "    return []\n",
        "  \n",
        "  # If not given, pick a start node at random.\n",
        "  if not start_node:\n",
        "    start_node = random.choice(list(graph.keys()))\n",
        "  \n",
        "  \n",
        "  weights = np.array(\n",
        "      list(markov_graph[start_node].values()),\n",
        "      dtype=np.float64)\n",
        "  # Normalize word counts to sum to 1.\n",
        "  weights /= weights.sum()\n",
        "\n",
        "  # Pick a destination using weighted distribution.\n",
        "  choices = list(markov_graph[start_node].keys())\n",
        "  chosen_word = np.random.choice(choices, None, p=weights)\n",
        "  \n",
        "  return [chosen_word] + walk_graph(\n",
        "      graph, distance=distance-1,\n",
        "      start_node=chosen_word)\n",
        "  \n",
        "for i in range(10):\n",
        "  print(' '.join(walk_graph(\n",
        "      markov_graph, distance=12)), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "was with each other of communication it kitty and such a doubt \n",
            "\n",
            "when the country ensued made for she cried miss elizabeth that had \n",
            "\n",
            "it would have taken a valuable neighbour lady s steady friendship replied \n",
            "\n",
            "on these recollections that he considered as well is but her companions \n",
            "\n",
            "and laugh that i only headstrong and what lydia s mr darcy \n",
            "\n",
            "till supper his it a part us yesterday se nnight elizabeth had \n",
            "\n",
            "on that he that whatever she thus addressed them that he might \n",
            "\n",
            "countenance of both joy jane when it which mr darcy was suddenly \n",
            "\n",
            "woods to me you know him at five years longer be adapted \n",
            "\n",
            "unless charlotte s letter though she did before they must give her \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhlLSLTi4pgy"
      },
      "source": [
        "And that's it for a basic Markov Chain! There are a lot of enhancements that\n",
        "could be made from here, but hopefully this demonstrates that you can implement\n",
        "a Markov Chain text generator with just a couple dozen lines of Python."
      ]
    }
  ]
}
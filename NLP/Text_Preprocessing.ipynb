{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Ppreprocessing.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6f2391eedd6640c7b317d8a1a74e6761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e5179e33a8cb4729b5883b94a516a8ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_53b36bade9f3479cb238d708ca78c946",
              "IPY_MODEL_dd102d14513f447aa0c8d35523172d29"
            ]
          }
        },
        "e5179e33a8cb4729b5883b94a516a8ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53b36bade9f3479cb238d708ca78c946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c547dbec0d234742a87609b7aa2c0132",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df9e07463b834312bcb72d71b9f8276f"
          }
        },
        "dd102d14513f447aa0c8d35523172d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_acba4621d88b4174b790e1f1d7838579",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 745kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1c031064dc34858b662192d32453961"
          }
        },
        "c547dbec0d234742a87609b7aa2c0132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df9e07463b834312bcb72d71b9f8276f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acba4621d88b4174b790e1f1d7838579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1c031064dc34858b662192d32453961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f61fbaadb162415c9dff85ea180e136f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_997186c85f604e71b835ee9ccecdeffb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cf28ffa1d0ac449aa78143248a5f8bbe",
              "IPY_MODEL_630ecf88f0854a0fa18a5008606c43d8"
            ]
          }
        },
        "997186c85f604e71b835ee9ccecdeffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf28ffa1d0ac449aa78143248a5f8bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fef2cfa269474a70b43d9aa7b44146e5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18a0df8ccc2c49c991f9fd6edc47fc02"
          }
        },
        "630ecf88f0854a0fa18a5008606c43d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ac7a337a50e47a39714795c49238a8f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.46kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67bbd5eec02a44348fb61046ef5bc5ff"
          }
        },
        "fef2cfa269474a70b43d9aa7b44146e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18a0df8ccc2c49c991f9fd6edc47fc02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ac7a337a50e47a39714795c49238a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67bbd5eec02a44348fb61046ef5bc5ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2a93451fa5046fd95be05ab886d89e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c3313e12fb7b45b8b872f84b148c4620",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b03b59d41c4b4e07a7165a71df984fa0",
              "IPY_MODEL_1027b7caf35343908bd5da991d6a52cd"
            ]
          }
        },
        "c3313e12fb7b45b8b872f84b148c4620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b03b59d41c4b4e07a7165a71df984fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cadeb47a852549b79ac781c4f28c74c9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90720ca28c66426593435d6e9c9651ab"
          }
        },
        "1027b7caf35343908bd5da991d6a52cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0f071d5f4094950a89cc5b5e56638da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:22&lt;00:00, 19.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1295dc7e2984eaba00fccae5d130ef1"
          }
        },
        "cadeb47a852549b79ac781c4f28c74c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90720ca28c66426593435d6e9c9651ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0f071d5f4094950a89cc5b5e56638da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1295dc7e2984eaba00fccae5d130ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/u6yuvi/DL-POC/blob/main/NLP/Text_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBMkqfqKNyAU"
      },
      "source": [
        "Setup Gdrive + Kaggle CLI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgokDk9fNwPy",
        "outputId": "188249c2-4241-4a72-bb13-8d2175a3cf40"
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/gdrive')\n",
        "#* updating filepath to your Google Drive\n",
        "\n",
        "# #Make sure you have this path available in your google drive\n",
        "# filepath=\"/content/gdrive/My Drive/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "Z7dCGXtwOMnn",
        "outputId": "7bd9a5da-6b24-48da-f584-076e5a4342ca"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5ef72910-8fee-4856-8778-e3be1d1f2548\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5ef72910-8fee-4856-8778-e3be1d1f2548\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"u6yuvi\",\"key\":\"62a8a2d8ea2f0d4d01b1bd812b047418\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpDNBiVfOia_"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCJYW449OWNO",
        "outputId": "1167ae37-2d65-42d2-97b2-5153a97cd1de"
      },
      "source": [
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content\n",
            " 60% 14.0M/23.4M [00:00<00:00, 25.1MB/s]\n",
            "100% 23.4M/23.4M [00:00<00:00, 47.8MB/s]\n",
            "Downloading test_labels.csv.zip to /content\n",
            "  0% 0.00/1.46M [00:00<?, ?B/s]\n",
            "100% 1.46M/1.46M [00:00<00:00, 99.5MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
            "100% 1.39M/1.39M [00:00<00:00, 94.3MB/s]\n",
            "Downloading train.csv.zip to /content\n",
            " 34% 9.00M/26.3M [00:00<00:00, 30.6MB/s]\n",
            "100% 26.3M/26.3M [00:00<00:00, 66.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfVmc0IIPHfO"
      },
      "source": [
        "!unzip -qq train.csv.zip\n",
        "#!unzip -qq test.zip"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_vjhWxAPen-"
      },
      "source": [
        "#Install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZcfPdV_Pdxg",
        "outputId": "3f5eb95c-0e6c-4a82-d0ae-8e39f05ebc89"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4MB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 16.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 61.6MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VjVslxMP9ni"
      },
      "source": [
        "!pip install -U -q watermark"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0dIrQ5xQGWW",
        "outputId": "d3dc7f10-2030-48d4-d289-b29d34dfee9f"
      },
      "source": [
        "%reload_ext watermark\n",
        "%watermark -v -p pandas,numpy,transformers"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPython 3.6.9\n",
            "IPython 5.5.0\n",
            "\n",
            "pandas 1.1.5\n",
            "numpy 1.18.5\n",
            "transformers 4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRWFIpp4QNLE"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WOagNfNPVfY"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPWWfqC6PMIq"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from pylab import rcParams\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch import nn , optim\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "%matplotlib inline"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPtrNzKQCqsb",
        "outputId": "4c166e45-d6af-4969-8270-f1cd5904258a"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbkjC_JDPaME",
        "outputId": "43620e92-81ed-460b-8fab-440faecb94e1"
      },
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "df.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(159571, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0MsZnytPnBA",
        "outputId": "6643dd4e-09f3-41b4-e326-a1a5448d4974"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count   Dtype \n",
            "---  ------         --------------   ----- \n",
            " 0   id             159571 non-null  object\n",
            " 1   comment_text   159571 non-null  object\n",
            " 2   toxic          159571 non-null  int64 \n",
            " 3   severe_toxic   159571 non-null  int64 \n",
            " 4   obscene        159571 non-null  int64 \n",
            " 5   threat         159571 non-null  int64 \n",
            " 6   insult         159571 non-null  int64 \n",
            " 7   identity_hate  159571 non-null  int64 \n",
            "dtypes: int64(6), object(2)\n",
            "memory usage: 9.7+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "WZ9L15c_PocW",
        "outputId": "370aba11-ae89-4904-db03-2612bcdb8ff9"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IKF-kjtDRwz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "023b24e2-dae0-4218-e806-fff5bbcc679e"
      },
      "source": [
        "sns.countplot(df.toxic)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa0b96578d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEGCAYAAACpXNjrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAVWUlEQVR4nO3df8xe5X3f8fcndiHJFgIEj6Q2qb3ESuXQZgEP3GWqqtCBYW2NWpLC2tpNLbwIsnZTshQ6KY5IkBIlKwtLguQFBzuKIJQ2w+tgrgdp6baY8BASfpbxlDTBHj9czI+sjKSm3/1xX09yxzx+eLCv57794/2Sjp5zvtd1zrmOZOnjc85133eqCkmSenrFuAcgSTr8GC6SpO4MF0lSd4aLJKk7w0WS1N38cQ/gYHHCCSfU4sWLxz0MSTqk3HnnnX9dVQv2rhsuzeLFi5mYmBj3MCTpkJLk29PVfSwmSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOT+h3dOq/3TzuIeggdOcnVo97CNLIeeciSerOcJEkdTdn4ZJkY5Inktw7Tdv7k1SSE9p2klyZZDLJ3UlOGeq7JslDbVkzVD81yT1tnyuTpNWPT7Kt9d+W5Li5ukZJ0vTm8s7lGmDl3sUkJwFnAt8ZKp8NLG3LOuCq1vd4YD1wOnAasH4oLK4CLhzab+pclwC3VNVS4Ja2LUkaoTkLl6q6Ddg9TdMVwAeBGqqtAjbXwHbg2CRvAM4CtlXV7qp6CtgGrGxtx1TV9qoqYDNw7tCxNrX1TUN1SdKIjPSdS5JVwM6q+uZeTQuBR4a2d7TaTPUd09QBTqyqR9v6Y8CJM4xnXZKJJBO7du16uZcjSdqHkYVLklcDvwd8aFTnbHc1NUP7hqpaXlXLFyx40Q+pSZL20yjvXN4ELAG+meSvgEXA15O8HtgJnDTUd1GrzVRfNE0d4PH22Iz294nuVyJJmtHIwqWq7qmqf1BVi6tqMYNHWadU1WPAFmB1mzW2AnimPdraCpyZ5Lj2Iv9MYGtrezbJijZLbDVwYzvVFmBqVtmaobokaUTmcirytcBXgbck2ZFk7QzdbwIeBiaB/wRcBFBVu4GPAHe05bJWo/X5XNvnL4GbW/1jwD9L8hDw821bkjRCc/b1L1V1wUu0Lx5aL+DiffTbCGycpj4BnDxN/UngjJc5XElSR35CX5LUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdTdn4ZJkY5Inktw7VPtEkr9IcneSLyc5dqjt0iSTSR5MctZQfWWrTSa5ZKi+JMntrf6lJEe1+tFte7K1L56ra5QkTW8u71yuAVbuVdsGnFxVPw38b+BSgCTLgPOBt7Z9PptkXpJ5wGeAs4FlwAWtL8DHgSuq6s3AU8DaVl8LPNXqV7R+kqQRmrNwqarbgN171f6kqva0ze3Aora+Criuqr5XVd8CJoHT2jJZVQ9X1feB64BVSQK8E7ih7b8JOHfoWJva+g3AGa2/JGlExvnO5beAm9v6QuCRobYdrbav+uuAp4eCaqr+I8dq7c+0/pKkERlLuCT5d8Ae4IvjOP/QONYlmUgysWvXrnEORZIOKyMPlyS/CfwC8GtVVa28EzhpqNuiVttX/Ung2CTz96r/yLFa+2tb/xepqg1Vtbyqli9YsOAAr0ySNGWk4ZJkJfBB4Jeq6rmhpi3A+W2m1xJgKfA14A5gaZsZdhSDl/5bWih9BTiv7b8GuHHoWGva+nnArUMhJkkagfkv3WX/JLkW+DnghCQ7gPUMZocdDWxr79i3V9V7q+q+JNcD9zN4XHZxVb3QjvM+YCswD9hYVfe1U/wucF2SjwJ3AVe3+tXAF5JMMphQcP5cXaMkaXpzFi5VdcE05aunqU31vxy4fJr6TcBN09QfZjCbbO/688C7XtZgJUld+Ql9SVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSerOcJEkdWe4SJK6M1wkSd0ZLpKk7gwXSVJ3hoskqTvDRZLUneEiSepuzsIlycYkTyS5d6h2fJJtSR5qf49r9SS5MslkkruTnDK0z5rW/6Eka4bqpya5p+1zZZLMdA5J0ujM5Z3LNcDKvWqXALdU1VLglrYNcDawtC3rgKtgEBTAeuB04DRg/VBYXAVcOLTfypc4hyRpROYsXKrqNmD3XuVVwKa2vgk4d6i+uQa2A8cmeQNwFrCtqnZX1VPANmBlazumqrZXVQGb9zrWdOeQJI3IqN+5nFhVj7b1x4AT2/pC4JGhfjtabab6jmnqM53jRZKsSzKRZGLXrl37cTmSpOmM7YV+u+OocZ6jqjZU1fKqWr5gwYK5HIokHVFGHS6Pt0datL9PtPpO4KShfotabab6omnqM51DkjQiow6XLcDUjK81wI1D9dVt1tgK4Jn2aGsrcGaS49qL/DOBra3t2SQr2iyx1Xsda7pzSJJGZP5cHTjJtcDPASck2cFg1tfHgOuTrAW+Dby7db8JOAeYBJ4D3gNQVbuTfAS4o/W7rKqmJglcxGBG2quAm9vCDOeQJI3InIVLVV2wj6YzpulbwMX7OM5GYOM09Qng5GnqT053DknS6PgJfUlSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKm7WYVLkltmU5MkCWD+TI1JXgm8GjghyXFAWtMxwMI5Hpsk6RD1Uncu/xK4E/jJ9ndquRH49P6eNMm/SXJfknuTXJvklUmWJLk9yWSSLyU5qvU9um1PtvbFQ8e5tNUfTHLWUH1lq00muWR/xylJ2j8zhktVfaqqlgAfqKp/WFVL2vK2qtqvcEmyEPhtYHlVnQzMA84HPg5cUVVvBp4C1rZd1gJPtfoVrR9JlrX93gqsBD6bZF6SecBngLOBZcAFra8kaURmfCw2par+Y5J/Aiwe3qeqNh/AeV+V5G8ZPHZ7FHgn8C9a+ybgw8BVwKq2DnAD8OkkafXrqup7wLeSTAKntX6TVfUwQJLrWt/793OskqSXaVbhkuQLwJuAbwAvtHIBLztcqmpnkk8C3wH+H/AnDB61PV1Ve1q3Hfzwnc5C4JG2754kzwCva/XtQ4ce3ueRveqn7+O61gHrAN74xje+3EuRJO3DrMIFWA4sq6o60BO2iQGrgCXA08AfMHisNXJVtQHYALB8+fIDvjZJ0sBsP+dyL/D6Tuf8eeBbVbWrqv4W+CPgHcCxSabCbhGws63vBE4CaO2vBZ4cru+1z77qkqQRmW24nADcn2Rrki1Ty36e8zvAiiSvbu9OzmDwPuQrwHmtzxoGM9IAtrRtWvut7Q5qC3B+m022BFgKfA24A1jaZp8dxeCl//6OVZK0H2b7WOzDvU5YVbcnuQH4OrAHuIvBo6n/ClyX5KOtdnXb5WrgC+2F/W4GYUFV3ZfkegbBtAe4uKpeAEjyPmArg5loG6vqvl7jlyS9tNnOFvuznietqvXA+r3KD/PD2V7DfZ8H3rWP41wOXD5N/SbgpgMfqSRpf8x2tth3GcwOAzgK+DHgb6rqmLkamCTp0DXbO5fXTK0PfcZkxVwNSpJ0aHvZ34pcA/8ZOOslO0uSjkizfSz2y0Obr2DwuZfn52REkqRD3mxni/3i0Poe4K8YPBqTJOlFZvvO5T1zPRBJ0uFjtj8WtijJl5M80ZY/TLJorgcnSTo0zfaF/ucZfMr9x9vyX1pNkqQXmW24LKiqz1fVnrZcAyyYw3FJkg5hsw2XJ5P8+tSPcSX5dQZfHilJ0ovMNlx+C3g38BiDH/Y6D/jNORqTJOkQN9upyJcBa6rqKYAkxwOfZBA6kiT9iNneufz0VLAAVNVu4O1zMyRJ0qFutuHyivYLksAP7lxme9cjSTrCzDYg/j3w1SR/0LbfxTRfdS9JEsz+E/qbk0wA72ylX66q++duWJKkQ9msH221MDFQJEkv6WV/5b4kSS/FcJEkdWe4SJK6G0u4JDk2yQ1J/iLJA0l+JsnxSbYleaj9Pa71TZIrk0wmuTvJKUPHWdP6P5RkzVD91CT3tH2ubD/NLEkakXHduXwK+G9V9ZPA24AHgEuAW6pqKXBL2wY4G1jalnXAVfCDz9qsB04HTgPWD30W5yrgwqH9Vo7gmiRJzcjDJclrgZ8Frgaoqu9X1dMMftlyU+u2CTi3ra8CNtfAduDYJG8AzgK2VdXu9u0B24CVre2YqtpeVQVsHjqWJGkExnHnsgTYBXw+yV1JPpfk7wEnVtWjrc9jwIltfSHwyND+O1ptpvqOaeovkmRdkokkE7t27TrAy5IkTRlHuMwHTgGuqqq3A3/DDx+BAdDuOGquB1JVG6pqeVUtX7DAn6eRpF7GES47gB1VdXvbvoFB2DzeHmnR/j7R2ncCJw3tv6jVZqovmqYuSRqRkYdLVT0GPJLkLa10BoNP/m8BpmZ8rQFubOtbgNVt1tgK4Jn2+GwrcGaS49qL/DOBra3t2SQr2iyx1UPHkiSNwLi+2fhfAV9MchTwMPAeBkF3fZK1wLcZ/DgZwE3AOcAk8FzrS1XtTvIR4I7W77L2UwAAFwHXAK8Cbm6LJGlExhIuVfUNYPk0TWdM07eAi/dxnI3AxmnqE8DJBzhMSdJ+8hP6kqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpu7GFS5J5Se5K8sdte0mS25NMJvlSkqNa/ei2PdnaFw8d49JWfzDJWUP1la02meSSUV+bJB3pxnnn8jvAA0PbHweuqKo3A08Ba1t9LfBUq1/R+pFkGXA+8FZgJfDZFljzgM8AZwPLgAtaX0nSiIwlXJIsAv458Lm2HeCdwA2tyybg3La+qm3T2s9o/VcB11XV96rqW8AkcFpbJqvq4ar6PnBd6ytJGpFx3bn8B+CDwN+17dcBT1fVnra9A1jY1hcCjwC09mda/x/U99pnX/UXSbIuyUSSiV27dh3oNUmSmpGHS5JfAJ6oqjtHfe69VdWGqlpeVcsXLFgw7uFI0mFj/hjO+Q7gl5KcA7wSOAb4FHBskvnt7mQRsLP13wmcBOxIMh94LfDkUH3K8D77qkuSRmDkdy5VdWlVLaqqxQxeyN9aVb8GfAU4r3VbA9zY1re0bVr7rVVVrX5+m022BFgKfA24A1jaZp8d1c6xZQSXJklqxnHnsi+/C1yX5KPAXcDVrX418IUkk8BuBmFBVd2X5HrgfmAPcHFVvQCQ5H3AVmAesLGq7hvplUjSEW6s4VJVfwr8aVt/mMFMr737PA+8ax/7Xw5cPk39JuCmjkOVJL0MfkJfktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR1Z7hIkrobebgkOSnJV5Lcn+S+JL/T6scn2Zbkofb3uFZPkiuTTCa5O8kpQ8da0/o/lGTNUP3UJPe0fa5MklFfpyQdycZx57IHeH9VLQNWABcnWQZcAtxSVUuBW9o2wNnA0rasA66CQRgB64HTgdOA9VOB1PpcOLTfyhFclySpGXm4VNWjVfX1tv5d4AFgIbAK2NS6bQLObeurgM01sB04NskbgLOAbVW1u6qeArYBK1vbMVW1vaoK2Dx0LEnSCIz1nUuSxcDbgduBE6vq0db0GHBiW18IPDK0245Wm6m+Y5r6dOdfl2QiycSuXbsO6FokST80tnBJ8veBPwT+dVU9O9zW7jhqrsdQVRuqanlVLV+wYMFcn06SjhhjCZckP8YgWL5YVX/Uyo+3R1q0v0+0+k7gpKHdF7XaTPVF09QlSSMyjtliAa4GHqiq3x9q2gJMzfhaA9w4VF/dZo2tAJ5pj8+2AmcmOa69yD8T2Nrank2yop1r9dCxJEkjMH8M53wH8BvAPUm+0Wq/B3wMuD7JWuDbwLtb203AOcAk8BzwHoCq2p3kI8Adrd9lVbW7rV8EXAO8Cri5LZKkERl5uFTV/wD29bmTM6bpX8DF+zjWRmDjNPUJ4OQDGKYk6QD4CX1JUnfjeCwmacS+c9lPjXsIOgi98UP3zNmxvXORJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujNcJEndGS6SpO4MF0lSd4aLJKk7w0WS1J3hIknqznCRJHVnuEiSujtswyXJyiQPJplMcsm4xyNJR5LDMlySzAM+A5wNLAMuSLJsvKOSpCPHYRkuwGnAZFU9XFXfB64DVo15TJJ0xJg/7gHMkYXAI0PbO4DT9+6UZB2wrm3+3yQPjmBsR4oTgL8e9yAOBvnkmnEPQT/Kf5tT1qfHUX5iuuLhGi6zUlUbgA3jHsfhKMlEVS0f9zikvflvczQO18diO4GThrYXtZokaQQO13C5A1iaZEmSo4DzgS1jHpMkHTEOy8diVbUnyfuArcA8YGNV3TfmYR1pfNyog5X/NkcgVTXuMUiSDjOH62MxSdIYGS6SpO4MF3Xl1+7oYJVkY5Inktw77rEcCQwXdePX7uggdw2wctyDOFIYLurJr93RQauqbgN2j3scRwrDRT1N97U7C8c0FkljZLhIkrozXNSTX7sjCTBc1JdfuyMJMFzUUVXtAaa+ducB4Hq/dkcHiyTXAl8F3pJkR5K14x7T4cyvf5EkdeediySpO8NFktSd4SJJ6s5wkSR1Z7hIkrozXKQxSHJskov2c9/3Jlnde0xST05FlsYgyWLgj6vq5DEPRZoT3rlI4/Ex4E1JvpHkE225N8k9SX4VIMmnknyorZ+V5LYkr0jy4SQfaPU3J/nvSb6Z5OtJ3jTGa5J+YP64ByAdoS4BTq6qf5TkV4D3Am8DTgDuSHIbcGlb/3PgSuCcqvq7JMPH+SLwsar6cpJX4n8YdZDwH6I0fv8UuLaqXqiqx4E/A/5xVT0HXAhsAz5dVX85vFOS1wALq+rLAFX1fNtHGjvDRTq4/RTwJPDj4x6I9HIYLtJ4fBd4TVv/c+BXk8xLsgD4WeBrSX4CeD/wduDsJKcPH6CqvgvsSHIuQJKjk7x6ZFcgzcBwkcagqp4E/meSe4GfAe4GvgncCnwQeBy4GvhAVf0fYC3wufZeZdhvAL+d5G7gfwGvH9ElSDNyKrIkqTvvXCRJ3RkukqTuDBdJUneGiySpO8NFktSd4SJJ6s5wkSR19/8BCGNUtBfm7pYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhIXf1-ESd_5"
      },
      "source": [
        "# Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T__rFu6zJ44-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518566a8-53cf-4f1c-f8d8-6535cca1d75b"
      },
      "source": [
        "df.comment_text.tolist()[:5]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\",\n",
              " \"D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\",\n",
              " \"Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\",\n",
              " '\"\\nMore\\nI can\\'t make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It\\'s listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"',\n",
              " \"You, sir, are my hero. Any chance you remember what page that's on?\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "wD2cCeapRw2x",
        "outputId": "68fb004d-a057-4a9b-dbf4-8c15448e5b61"
      },
      "source": [
        "#Length of the comments_text\n",
        "df.comment_text.apply(lambda x : len(x)).plot(kind = 'kde',xlim = (0,2000),figsize=(10,10))\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa0bc7d7898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAI/CAYAAADnUWiDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXTcZ333/c93Rvu+y7Il7/KW2LETJc4KCSFkawnchJJQ0gBhuZ+SFkp7twnt4endU3qXckNangZKgDQBWkIIaZOWQICQELLZcWLH8iZb3i3bkqx912jmev6YkaMosj2SZvSb5f06R8fSb37z03d0Tssn13V9r8uccwIAAED68HldAAAAAOYWARAAACDNEAABAADSDAEQAAAgzRAAAQAA0gwBEAAAIM1keF2AlyoqKtzixYu9LgMAAOCcXnvttVPOucpYPCutA+DixYu1ZcsWr8sAAAA4JzM7HKtnMQUMAACQZgiAAAAAaYYACAAAkGYIgAAAAGmGAAgAAJBmCIAAAABphgAIAACQZgiAAAAAaYYACAAAkGYIgAAAAGmGAAgAAJBmCIAAAABphgAIAACQZgiAAAAAaYYACAAAkGYIgAAAAGmGAAgAAJBmCIAAAABphgAIAACQZgiAAAAAaYYACAAAkGYIgAAAAGmGABhnQ6NBfes3+3XbAy/raOeg1+UAAAAow+sCUtmPXj2ir/5ir9r6RpThM939w6368acvU1YGuRsAAHiHJBInrx/p0l/8pFF1ZXl69NOX6Z8/fKHeONqt//Oz3V6XBgAA0hwjgHHy2GvHlJPp00Mfu1iFOZmSpI9dsVj/+uIhbVxSphvOr/G4QgAAkK4YAYyD4UBQ//XGcd14fs3p8CdJ9964WhfUleiexxs1HAh6WCEAAEhnBMA4+MWuVvUNj+mDF9W+5XpWhk9/9p4V6h4M6LmmNo+qAwAA6S6uAdDMbjCzJjNrNrN7png928x+FHl9k5ktnvDavZHrTWZ2feRanZk9a2a7zGynmX12wv1/bWYtZrYt8nVTPD/b2Tz22jEtKMnVpUvL3/baZUvLVVGQrSe2HfegMgAAgDgGQDPzS7pf0o2S1ki63czWTLrtLkldzrnlku6T9OXIe9dIuk3SeZJukPSNyPPGJP2pc26NpEslfWbSM+9zzq2PfD0Vr892Nid7hvXCvnZ94MIF8vnsba9n+H36nXU1emZPm3qHAx5UCAAA0l08RwAvkdTsnDvgnBuV9IikWybdc4ukhyPfPybpWjOzyPVHnHMjzrmDkpolXeKcO+Gce12SnHN9knZLWhDHzzBtj289ppCTPjBp+neiW9bP1+hYSE/vODmHlQEAAITFMwAukHR0ws/H9Pawdvoe59yYpB5J5dG8NzJdvEHSpgmX7zaz7Wb2oJmVzv4jTN9/bm3RJYvLtKg8/4z3rK8r0cKyPD35BtPAAABg7iVlE4iZFUj6iaTPOed6I5e/KWmZpPWSTkj66hne+ykz22JmW9rb22NaV89gQHtb+3X1qsqz3mdmumX9fL3YfEptfcMxrQEAAOBc4hkAWyTVTfi5NnJtynvMLENSsaSOs73XzDIVDn//5px7fPwG51yrcy7onAtJ+rbCU9Bv45x7wDnX4JxrqKw8e1Cbrh3HeyRJaxcUn/PeW9bPV8hJP91+IqY1AAAAnEs8A+CrkurNbImZZSnc1PHkpHuelHRn5PtbJf3aOeci12+LdAkvkVQvaXNkfeB3Je12zn1t4oPMbOLOyu+XtCPmn+gcGlvCAfD8+ecOgMurCrW6pkhPNRIAAQDA3IrbSSDOuTEzu1vS05L8kh50zu00s7+RtMU596TCYe77ZtYsqVPhkKjIfY9K2qVw5+9nnHNBM7tS0h2SGs1sW+RXfSHS8fsPZrZekpN0SNKn4/XZzqSxpUe1pbkqzc+K6v53rKjQgy8c1NBoULlZ/jhXBwAAEBbXo+AiweypSde+OOH7YUkfPMN7vyTpS5OuvSDp7XurhF+7Y7b1ztaOlp6opn/HXbq0XN/6zQG9fqRLVyyviGNlAAAAb0rKJpBE1DMU0OGOQZ0/jQDYsKhUPpNeOdARx8oAAADeigAYIztbom8AGVeYk6m1C4q16UBnvMoCAAB4GwJgjDTOIABK0sal5dp2tFvDgWA8ygIAAHgbAmCMNLb0aEFJ9A0g4y5dWqbRYEivH+mKU2UAAABvRQCMkek2gIxrWFwWWQfINDAAAJgbBMAY6B0O6FDHoNbWTj8AFuVk6rz5xdpEIwgAAJgjBMAY2DG+AfQMRgAlaeOSMm1lHSAAAJgjBMAY2DHDBpBxly4t1+hYSNuOdseyLAAAgCkRAGOgsaVXC0pyVTbNBpBxFy8pk7EfIAAAmCMEwBg4dGpAy6sKZvz+4txM1VcVaPuxnhhWBQAAMDUCYAwc7hjQwrK8WT1j7YISbT/WI+dcjKoCAACYGgFwlnoGA+odHpt1AFxXW6xT/SM60TMco8oAAACmRgCcpSOdg5KkheWzD4CSmAYGAABxRwCcpcOdA5I06xHA1TVFyvCZGlvoBAYAAPFFAJyl8RHAulkGwJxMv1ZUFzICCAAA4o4AOEtHOwdVUZClguyMWT9rXW2xGltoBAEAAPFFAJylwx2Dsx79G7e2tljdgwEd6xqKyfMAAACmQgCcpSOdg7Ne/zfugtoSSdIbx1gHCAAA4ocAOAuBYEjHu4e0KEYBcEV1obL8PjWyDhAAAMQRAXAWWrqGFHKzbwAZl5Xh0+oaGkEAAEB8EQBn4fQegDEKgFJ4HeCOlh6FQjSCAACA+CAAzsJ4AFxUnh+zZ65bUKK+kTEd6hiI2TMBAAAmIgDOwpHOQWVl+FRVmB2zZ66NnAjS2MI0MAAAiA8C4Cwc6RhUXWmufD6L2TOXVRYo02/afaIvZs8EAACYiAA4C0c6B2M6/SuFG0GWVxVqz8nemD4XAABgHAFwhpxzMd0DcKLV8wq1+wQBEAAAxAcBcIa6BgPqHxmL2RYwE62uKVJr74g6B0Zj/mwAAAAC4Ayd7gCOQwBcVVMoSdrDKCAAAIgDAuAMnd4DsDwOAXBekSRp90kaQQAAQOwRAGfoaCQA1pXGPgBWFmaroiCbdYAAACAuCIAzdLJnWCV5mcrN8sfl+atr6AQGAADxQQCcodbeYVUX5sTt+atrirS3tV9jwVDcfgcAAEhPBMAZau0bUVVR7E4AmWzVvEKNjoV08BRHwgEAgNgiAM5QW++wqoviOwIoSbtYBwgAAGKMADgDoZBTW9+IquM4ArisskAZPtMeOoEBAECMEQBnoGNgVMGQi+sIYPhIuAI6gQEAQMwRAGegtXdYklQVxyYQKTwNvOcEI4AAACC2CIAz0NYXDoDxnAKWwo0gJ3uH1cWRcAAAIIYIgDPQ2jsiSXGdApaklfPCR8LtbWUUEAAAxA4BcAbGp4ArC+M7AlhfHQmAbf1x/T0AACC9EABnoLV3RBUFWcr0x/fPN784RwXZGdrHCCAAAIghAuAMtPUOx70BRJLMTMurCrSvlRFAAAAQOwTAGTjZOxz3BpBx9VUF2tfGCCAAAIgdAuAMtPaOxL0BZNyK6kKd6h9VJ53AAAAgRgiA0xQIhtQxMKKqOQqA9dUFksQ6QAAAEDMEwGk61T8i56R5czgCKNEJDAAAYocAOE1v7gE4N2sAa+gEBgAAMUYAnKbxPQDnag3geCcwm0EDAIBYIQBOU9v4OcBzNAIoSSuqC9TMFDAAAIgRAuA0tfaOyO8zlefPZQCkExgAAMQOAXCaWnuHVVmQLb/P5ux3Lq8KdwIzDQwAAGKBADhNrX0jc9YAMm68E3gf08AAACAGCIDT1NY7PGd7AI6jExgAAMQSAXCaWufwGLhxdAIDAIBYIgBOw8hYUF2DAVUXzu0IoBTuBN7XyhQwAACYPQLgNLSd3gTaiwBYqI6BUXX0j8z57wYAAKmFADgNbX1zvwfguHoaQQAAQIwQAKehvS88+lZR4EEAjGwFQyMIAACYLQLgNHRENmL2IgDWFOeoMDuDEUAAADBrBMBp6OgPB8DS/Mw5/91mpuXVdAIDAIDZIwBOQ+fAqApzMpSd4ffk96+oKqQTGAAAzBoBcBpO9Y+oPD/Ls99fX11AJzAAAJg1AuA0dA6MqtyD9X/j6AQGAACxQACcho7+UZV5OAK4oppOYAAAMHsEwGnoGBhVRYF3AXBeUbgTeC/rAAEAwCwQAKMUCjl1DXo7AjjeCbyvjRFAAAAwcwTAKPUMBRQMOZXle7cGUKITGAAAzB4BMEpvbgLt3QigRCcwAACYPQJglMYDl5dTwNKbncCsAwQAADNFAIxSZ2QEsNzrKeBIJ3Az6wABAMAMEQCjND4FXO7xFDCdwAAAYLYIgFE6fQ5wnrcB0MxUz5nAAABgFgiAUeocGFFRToayMrz/k9VXFWp/OyOAAABgZrxPM0nilMfHwE1UX12gU/2jp9clAgAATAcBMEqd/aMq97gDeNyyqvFGEEYBAQDA9BEAo9Q54O0pIBPVRwIgJ4IAAICZIABGqWNgJGGmgOcX5yovy88IIAAAmBECYBRCIafOgcSZAvb5TMurCgiAAABgRgiAUegeCijkvD8FZKLlVQWcCQwAAGaEABiFzoHwMXBebwI9UX1VoU72Dqt3OOB1KQAAIMkQAKMwvgm018fATVRPJzAAAJghAmAUEuUYuInqx88EZhoYAABMEwEwCqcDYAKtAawtzVNWhk/NnAgCAACmiQAYhY7+8BrA0gQKgH6faVllgfZxJjAAAJgmAmAUOgdGVZybqUx/Yv256qsKtI81gAAAYJoSK9EkqI4E2gNwovqqAh3rGtLg6JjXpQAAgCRCAIxCR/9IQjWAjBtvBNnfNuBxJQAAIJkQAKOQSOcAT7S8qlASZwIDAIDpiWsANLMbzKzJzJrN7J4pXs82sx9FXt9kZosnvHZv5HqTmV0fuVZnZs+a2S4z22lmn51wf5mZ/dLM9kX+LY3V5+joH02Yc4AnWlSep0y/sQ4QAABMS9wCoJn5Jd0v6UZJayTdbmZrJt12l6Qu59xySfdJ+nLkvWsk3SbpPEk3SPpG5Hljkv7UObdG0qWSPjPhmfdIesY5Vy/pmcjPsxYKOXUNJuYawEy/T0sq8tkMGgAATEs8RwAvkdTsnDvgnBuV9IikWybdc4ukhyPfPybpWjOzyPVHnHMjzrmDkpolXeKcO+Gce12SnHN9knZLWjDFsx6W9L5YfIhEPAd4ouVVBQRAAAAwLfEMgAskHZ3w8zG9Gdbedo9zbkxSj6TyaN4bmS7eIGlT5FK1c+5E5PuTkqpn+wEkqWswvAl0aV6iBsBCHe4Y0HAg6HUpAAAgSSRlE4iZFUj6iaTPOed6J7/unHOS3Bne+ykz22JmW9rb28/5u7oHA5Kk4rzMWdUcL/VVBQo56eApOoEBAEB04hkAWyTVTfi5NnJtynvMLENSsaSOs73XzDIVDn//5px7fMI9rWZWE7mnRlLbVEU55x5wzjU45xoqKyvP+SG6E3wEcHwrGBpBAABAtOIZAF+VVG9mS8wsS+Gmjicn3fOkpDsj398q6deR0bsnJd0W6RJeIqle0ubI+sDvStrtnPvaWZ51p6QnYvEhuiIjgKUJOgK4pCJfPpOaORIOAABEKSNeD3bOjZnZ3ZKeluSX9KBzbqeZ/Y2kLc65JxUOc983s2ZJnQqHREXue1TSLoU7fz/jnAua2ZWS7pDUaGbbIr/qC865pyT9vaRHzewuSYcl/V4sPsf4CGBJgo4AZmf4tbg8nxFAAAAQtbgFQEmKBLOnJl374oTvhyV98Azv/ZKkL0269oIkO8P9HZKunWXJb9M9GJDPpMLsuP6pZoVOYAAAMB1J2QQyl7oGR1WSlyWfb8rcmRDqqwt08NSAAsGQ16UAAIAkQAA8h+7BgEoSdP3fuOVVBRoLOR3uoBMYAACcGwHwHLqHRhO2A3hc/fiZwK1MAwMAgHMjAJ5D10BAJbmJPQK4rLJAZmwFAwAAokMAPIfuyBrARJab5VdtaS4BEAAARIUAeA5dg4GE3QNwovqqQu1jL0AAABAFAuBZDAeCGgoEE74JRAofCXfg1ICCoSlPwAMAADiNAHgWPUPhU0ASfQpYCncCj46FdLRz0OtSAABAgiMAnkVXgp8DPFF9dbgTeC/TwAAA4BwIgGfRneDnAE9UX1UgiU5gAABwbgTAsxg/B7g4CQJgfnaGaktz1XSSEUAAAHB2BMCz6Do9Apj4U8CStLK6kClgAABwTgTAs0imNYCStGJeofa393MmMAAAOCsC4Fn0DAaUleFTTmZy/JlWVhcqEHQ6dIozgQEAwJklR7LxSNfgqErzMmVmXpcSlfrqcCNIE9PAAADgLAiAZxE+BSQ5pn+l8JnAPpP2ttIJDAAAzowAeBY9g4GkOAVkXE6mX4sr8rWXTmAAAHAWBMCz6BocVUlu8owASnQCAwCAcyMAnkXXYECl+ckzAihJK6oLdahjQMOBoNelAACABEUAPAPnnLoHR5PiHOCJVs4rVMhJzZwIAgAAzoAAeAYDo0GNhVxSHAM30YpIJzDTwAAA4EwIgGfQNRDeBDrZ1gAuKs9Xlt9HJzAAADgjAuAZdEeOgUumLmBJyvT7tLQynxFAAABwRgTAM+geihwDl59cI4BSeB1gE1vBAACAMyAAnkHX+AhgbnKNAErhTuCW7iH1DQe8LgUAACQgAuAZdA9G1gAmWRewFA6AkrSPTmAAADAFAuAZdA0k5xpAKbwZtCROBAEAAFMiAJ5B99CoCrMzlOlPvj9RbWmucjP9dAIDAIApJV+6mSPdgwEVJ+HonyT5fKYV1QV0AgMAgCkRAM+ga3BUpUm4/m/ciupCNREAAQDAFAiAZ9A9GEjK9X/jVs4rVHvfiDojG1oDAACMIwCeQTKeAzxR/XgjCKOAAABgEgLgGfQMBVScm+F1GTO2kgAIAADOgAA4BeeceofHVJyEm0CPqy7KVlFOBgEQAAC8DQFwCv0jYwqGXFIHQDPTynmF2nuSrWAAAMBbEQCn0DMU3gQ6mQOg9GYnsHPO61IAAEACIQBOoXdoTFJqBMCeoYDa+ka8LgUAACQQAuAUxkcAi1IgAEpSE0fCAQCACQiAU0idKeACSXQCAwCAtyIATqF3fAQwJ7kDYHlBtioKshkBBAAAb0EAnMLpEcAkPglk3Mp5nAkMAADeigA4hZ6hgHwmFWQl70bQ41ZUF2pva7+CITqBAQBAGAFwCj1DARXlZsrnM69LmbXVNUUaCgR1uGPA61IAAECCIABOIXwMXPJP/0rSmpoiSdLuE0wDAwCAMALgFHqHUycALq8qkN9n2nOy1+tSAABAgiAATiGVRgBzMv1aWpGv3ScIgAAAIIwAOIXxNYCpYnVNEVPAAADgNALgFHqHAkm/B+BEq2uK1NI9dHp7GwAAkN4IgJM451JqCliSVtWEj4TbwzQwAAAQAfBthgJBBYIupQLgm53ABEAAAEAAfJtUOQd4oqrCbJXlZ2kPR8IBAAARAN8mFQOgmWnVvEJGAAEAgCQC4Nv0Do1JSq0AKIUbQZpa+zgSDgAAEAAnS8URQCkcAIcDIR08xZFwAACkOwLgJOMBsCg3w+NKYmv1eCcwJ4IAAJD2CICTpOoI4PKqAmX4jHWAAACAADjZeAAsTKGNoCUpO8OvZZUF2nWcAAgAQLojAE7SOxRQYU6G/D7zupSYO29+kXYSAAEASHsEwElS7RSQidbML1Jb34ja+0a8LgUAAHiIADhJKgfA8xcUS5J2Hu/xuBIAAOAlAuAkvSkcANfMDx8JxzQwAADpjQA4SSqPABblZGphWR4jgAAApDkC4CQ9QwEVpVgH8EQ0ggAAAALgJD1DARXnpXYAPNwxqN7hgNelAAAAjxAAJxgOBDUyFkrZKWBJOm9+uBFkN6OAAACkLQLgBL2nj4FL5QBIIwgAAOmOADhBqh4DN1FVUY4qC7O1g0YQAADSFgFwgnQIgFJ4FJAj4QAASF8EwAnGGyPSIQDua+vXcCDodSkAAMADBMAJ0mcEsFjBkNPe1j6vSwEAAB4gAE7QMxhpAsnJ8LiS+BpvBNnRwjQwAADpiAA4Qc/QmKTU7gKWpIVleSrMyVBjC40gAACkIwLgBD1DAeVn+ZXpT+0/i5lpXW2xGlu6vS4FAAB4ILWTzjSl8jnAk62rLVHTyT4aQQAASEMEwAl6hgIpP/07bt2CYgWCTk0naQQBACDdEAAn6E2jEcC1teEj4bazDhAAgLRDAJygdzh9AuCCklyV5Wep8RjrAAEASDcEwAnSaQ2gmWntgmJtP8YIIAAA6YYAOEE6rQGUpHW1xdrX1q+hURpBAABIJwTAiEAwpMHRYNqMAErS2gXhE0F2nWBDaAAA0gkBMCJdjoGbaF1tiSSxDhAAgDRDAIxIxwBYXZStysJsOoEBAEgzBMCIdAyAZqZ1C4rVSCMIAABphQAYMR4A06kJRApPAze392tgZMzrUgAAwBwhAEb0puEIoBTuBHZO2sE0MAAAaYMAGNF7egQww+NK5ta6yIkg247SCAIAQLogAEak4xpASSovyNbCsjwCIAAAaYQAGNEzFFBOpk/ZGX6vS5lzGxaWaOsRAiAAAOkirgHQzG4wsyYzazaze6Z4PdvMfhR5fZOZLZ7w2r2R601mdv2E6w+aWZuZ7Zj0rL82sxYz2xb5umk6tabTMXCTra8r0cneYZ3sGfa6FAAAMAfiFgDNzC/pfkk3Sloj6XYzWzPptrskdTnnlku6T9KXI+9dI+k2SedJukHSNyLPk6SHItemcp9zbn3k66np1JvuAVCSth3t8rgSAAAwF+I5AniJpGbn3AHn3KikRyTdMumeWyQ9HPn+MUnXmplFrj/inBtxzh2U1Bx5npxzz0vqjHWx6RwA18wvUpbfp62sAwQAIC3EMwAukHR0ws/HItemvMc5NyapR1J5lO+dyt1mtj0yTVw6nWJ7hsbSNgBmZ/i1en4R6wABAEgTqdQE8k1JyyStl3RC0lenusnMPmVmW8xsS3t7++nrvUOBtNsEeqINdSVqPNajsWDI61IAAECcxTMAtkiqm/BzbeTalPeYWYakYkkdUb73LZxzrc65oHMuJOnbikwZT3HfA865BudcQ2Vl5enrvUMBFeWkcQBcWKKhQFB7W/u9LgUAAMRZPAPgq5LqzWyJmWUp3NTx5KR7npR0Z+T7WyX92jnnItdvi3QJL5FUL2nz2X6ZmdVM+PH9knac6d7JgiGnvpH0nQKW3mwE2UojCAAAKS9uATCypu9uSU9L2i3pUefcTjP7GzN7b+S270oqN7NmSZ+XdE/kvTslPSppl6SfS/qMcy4oSWb2Q0kvS1ppZsfM7K7Is/7BzBrNbLukayT9SbS1pusxcBMtLMtTWX6WtrEOEACAlBfXc88iW7E8NenaFyd8Pyzpg2d475ckfWmK67ef4f47Zlpnup4CMpGZ6YLaYk4EAQAgDaRSE8iMEQDDNiwsVXN7/+m/BwAASE0EQE0IgHnpHQAvWlQq56StR1gHCABAKiMASuodZgRQCjeC+H2m1w4TAAEASGUEQDEFPC4/O0Orawq15RABEACAVEYA1JsBMJ33ARx30cJSbTvazYbQAACkMAKgwgEwy+9TTiZ/josWl2koENTuE31elwIAAOKExKM3j4EzM69L8VzDovARylsOd3pcCQAAiBcCoMIjgMW5cd0SMWnML8lVTXEOjSAAAKQwAqDGAyDr/8ZdtKiUAAgAQAojAIoAOFnDolKd6BlWS/eQ16UAAIA4IABK6h0aIwBO0LC4TJK05RDrAAEASEUEQIVHAIsIgKetmleovCy/XmcaGACAlJT2ATAUcuodZgp4ogy/T+vrSvQqG0IDAJCS0j4A9o2MyTlOAZnskiVl2n2y9/QxeQAAIHWkfQDsHT8FhAD4FpcsKZNz0muMAgIAkHLSPgByDvDUNtSVKtNv2nSQRhAAAFINAZAAOKXcLL/W1ZZo08EOr0sBAAAxRgAkAJ7RxiVlajzWo8HRMa9LAQAAMZT2AbCXAHhGlywp01jIaeuRbq9LAQAAMZT2AbCHJpAzumhRqXwm1gECAJBiCIBDAfl9pvwsv9elJJzCnEydN79Ym1kHCABASiEARs4BNjOvS0lIlywp09Yj3RoZC3pdCgAAiJGoAqCZPW5mN5tZygXG8QCIqW1cUqaRsZC2H+vxuhQAABAj0Qa6b0j6sKR9Zvb3ZrYyjjXNKc4BPruLF5dJkjYdYBoYAIBUEVUAdM79yjn3+5IulHRI0q/M7CUz+5iZJXV66mUE8KxK87O0al4hjSAAAKSQqKd0zaxc0kclfULSVkn/pHAg/GVcKpsjTAGf22XLyvXqoU7WAQIAkCKiXQP4H5J+KylP0u86597rnPuRc+6PJBXEs8B46x0eU3FuhtdlJLTLlpZrOBDSNvYDBAAgJUSbfL7tnHtq4gUzy3bOjTjnGuJQ15zpGQqoKIcRwLPZuLRcPpNePtChjUvLvS4HAADMUrRTwH87xbWXY1mIF0LOKRhyTAGfQ3FueD/Al/bTCAIAQCo46wigmc2TtEBSrpltkDS+WV6RwtPBSS0YcpI4Bi4aly8r14MvHtTQaFC5bJoNAEBSO9cU8PUKN37USvrahOt9kr4Qp5rmDAEwepctK9e3nj+gLYc7dVV9pdflAACAWThrAHTOPSzpYTP7gHPuJ3NU05whAEbv4sVlyvCZXt7fQQAEACDJnWsK+CPOuR9IWmxmn5/8unPua1O8LWmMB0A2gj63/OwMXVBXwjpAAABSwLmaQPIj/xZIKpziK6kxAjg9ly0tV2NLj/qGA16XAgAAZuFcU8Dfivz7v+emnLkVdJEAmEcAjMbly8r1z882a/PBTl27utrrcgAAwAxFuxH0P5hZkZllmtkzZtZuZh+Jd3HxFgw5mUkFWWwEHY0LF5UqO8OnF5pPeV0KAACYhWj3AXyPc65X0u8ofBbwckn/K15FzZVgyKkoJ1M+n537Zign069LlpTphX0EQAAAklm0AXB8iOxmST92zvXEqZ45xSbQ03fl8grta+vXyZ5hr0sBAAAzFG0A/G8z2yPpIknPmFmlpKRPAATA6cJHxR0AACAASURBVLuyvkKSmAYGACCJRRUAnXP3SLpcUoNzLiBpQNIt8SxsLgQdAXC6Vs8rUnl+ll7Y1+51KQAAYIam0/2wSuH9ACe+53sxrmdOMQI4fT6f6YrlFXqhuUPOOZmxfhIAgGQTbRfw9yX9X0lXSro48tUQx7rmRDDk2AR6Bq6sr9Cp/hHtOdnndSkAAGAGoh0BbJC0xrnIxnkpIhwA2QJmuq4aXwe475RW1xR5XA0AAJiuaJtAdkiaF89CvODEKSAzUVOcq2WV+fotjSAAACSlaIe/KiTtMrPNkkbGLzrn3huXquYQAXBmrqqv1COvHtFwIKicTL/X5QAAgGmINgD+dTyL8BIBcGauqq/QQy8d0pZDXae3hgEAAMkh2m1gfqPwCSCZke9flfR6HOuaMwTAmblsWbmy/D4919TmdSkAAGCaou0C/qSkxyR9K3JpgaT/jFdRc4kAODN5WRnauLRMz+1lP0AAAJJNtE0gn5F0haReSXLO7ZNUFa+i5hIBcOauXlml5rZ+He0c9LoUAAAwDdEGwBHn3Oj4D5HNoFNiSxgC4Mxds7JSkpgGBgAgyUQbAH9jZl+QlGtm10n6saT/il9Zc6cwhwA4U0sq8rWwLE/PNTENDABAMok2AN4jqV1So6RPS3pK0l/Fq6i54jOT38dRZjNlZrpmZaVe3H9Kw4Gg1+UAAIAoRdsFHFK46eMPnXO3Oue+nQqnghD+Zu/qlVUaDoS0+WCn16UAAIAonTUAWthfm9kpSU2Smsys3cy+ODflxRcBcPYuXVqu7AyfnmUdIAAASeNcI4B/onD378XOuTLnXJmkjZKuMLM/iXt1ceY3AuBs5Wb5denScv2GdYAAACSNcwXAOyTd7pw7OH7BOXdA0kck/UE8C5sLjADGxjUrK3Xg1IAOnRrwuhQAABCFcwXATOfcqckXnXPtkpK+fZYAGBtXrwxvCcl2MAAAJIdzBcDRGb6WFAiAsbG4Il9LKvI5FQQAgCSRcY7XLzCz3imum6ScONQzpwiAsXP1ykr9+6YjGg4ElZPp97ocAABwFmcdAXTO+Z1zRVN8FTrnmALGaVevrNLIWEgvH+jwuhQAAHAO0W4EnZLoAo6djUvKlJPp03N7WAcIAECiS+8AyAhgzORk+nX5sgo929SuFNgjHACAlEYARMxcs7JSRzoHdZDtYAAASGhpHQAzCIAx9eZ2MHQDAwCQyNI6ADICGFt1ZXlaVpnPsXAAACQ4AiBi6trV1XrlQId6hwNelwIAAM4grQMgYu+6NdUKBB1nAwMAkMAIgIipCxeWqjw/S7/c1ep1KQAA4AwIgIgpv8907eoqPbunTaNjIa/LAQAAUyAAIuauWzNPfSNj2nSQU0EAAEhEBEDE3JXLK5ST6WMaGACABEUARMzlZvl1VX2lfrWrlVNBAABIQARAxMV1a6p1vGdYO4/3el0KAACYhACIuLh2VZV8Jv2CaWAAABIOARBxUV6QrYsWlbIOEACABEQARNxct6Zau0/06mjnoNelAACACQiAiJvr1syTJP1qN6OAAAAkEgIg4mZJRb6WVxUwDQwAQIIhACKurltTrU0HO9UzGPC6FAAAEEEARFxdt6ZawZDTs01tXpcCAAAiCICIq/W1JaoszGYaGACABEIARFz5fKZ3r67Sc01tGhkLel0OAAAQARBz4Lo11RoYDeql/R1elwIAAEQAxBy4YnmFCrIz9PPGk16XAgAARADEHMjO8Ovdq6v09K6TCgRDXpcDAEDaIwBiTty4tkbdgwG9coBpYAAAvEYAxJx454pK5Wf59VTjCa9LAQAg7REAMSdyMv161+pqPb2zVWNMAwMA4Km4BkAzu8HMmsys2czumeL1bDP7UeT1TWa2eMJr90auN5nZ9ROuP2hmbWa2Y9Kzyszsl2a2L/JvaTw/G6bv5rXz1Dkwqk0HO70uBQCAtBa3AGhmfkn3S7pR0hpJt5vZmkm33SWpyzm3XNJ9kr4cee8aSbdJOk/SDZK+EXmeJD0UuTbZPZKecc7VS3om8jMSyDtXVCk3k2lgAAC8Fs8RwEskNTvnDjjnRiU9IumWSffcIunhyPePSbrWzCxy/RHn3Ihz7qCk5sjz5Jx7XtJUQ0gTn/WwpPfF8sNg9nKz/HrX6io9vfOkgiHndTkAAKSteAbABZKOTvj5WOTalPc458Yk9Ugqj/K9k1U758aHlk5Kqp5Z2Yinm86v0an+UW1mGhgAAM+kZBOIc85JmnKIycw+ZWZbzGxLe3v7HFeGa1ZVKifTp5/tYBoYAACvxDMAtkiqm/BzbeTalPeYWYakYkkdUb53slYzq4k8q0ZS21Q3OececM41OOcaKisro/woiJW8rAxds7JKP9vBNDAAAF6JZwB8VVK9mS0xsyyFmzqenHTPk5LujHx/q6RfR0bvnpR0W6RLeImkekmbz/H7Jj7rTklPxOAzIA5uWluj9r4RvXa4y+tSAABIS3ELgJE1fXdLelrSbkmPOud2mtnfmNl7I7d9V1K5mTVL+rwinbvOuZ2SHpW0S9LPJX3GOReUJDP7oaSXJa00s2NmdlfkWX8v6Toz2yfp3ZGfkYDetapK2Rk+uoEBAPCIhQfc0lNDQ4PbsmWL12WkpU9/f4u2He3Wy/dcK5/PvC4HAICEZ2avOecaYvGslGwCQeK7aW2NWntH9PoRpoEBAJhrBEB44l2rqpSV4dNTjSe9LgUAgLRDAIQnCnMy9Y76Sv1sxwmF6AYGAGBOEQDhmd+9oEYneoa1+RCbQgMAMJcIgPDMdWuqlZfl1xPbzrXFIwAAiCUCIDyTl5Wh68+bp59uP6GRsaDX5QAAkDYIgPDULevnq3d4TM81cSwfAABzhQAIT125vELl+VlMAwMAMIcIgPBUht+n31lXo1/tblPvcMDrcgAASAsEQHjulg0LNDoW0tM72BMQAIC5QACE5zbUlWhReZ6e2Hbc61IAAEgLBEB4zsx0ywXz9dL+U2rrHfa6HAAAUh4BEAnhvesXKOSkJ99gFBAAgHgjACIhLK8q0PkLipgGBgBgDhAAkTDet36BGlt6tL+93+tSAABIaQRAJIzfvWC+zKQntrInIAAA8UQARMKoLsrR5cvK9cQbx+Wc87ocAABSFgEQCeWW9Qt0uGNQ2452e10KAAApiwCIhHLD+fOUleHT468zDQwAQLwQAJFQinIydf158/TkG8c1HAh6XQ4AACmJAIiE88GLatUzFNCvdrd6XQoAACmJAIiEc8XyCtUU5+jHW455XQoAACmJAIiE4/eZPnBhrX67r10nezgaDgCAWCMAIiHdelGtQk76yeuMAgIAEGsEQCSkxRX5umRxmR577Rh7AgIAEGMEQCSsWxtqdfDUgLYc7vK6FAAAUgoBEAnr5rU1KsjO0CObj3pdCgAAKYUAiISVn52hW9bP139vP66ewYDX5QAAkDIIgEhot1+yUCNjIf3nNk4GAQAgVgiASGjnLyjW2gXF+uHmIzSDAAAQIwRAJLzbL1moPSf7tPVot9elAACQEgiASHjvXT9feVl+/XDTEa9LAQAgJRAAkfAKIs0g/7X9uHqGaAYBAGC2CIBICr+/cZGGAyH95DVOBgEAYLYIgEgK5y8o1oaFJfr+K4cVCtEMAgDAbBAAkTTuvGyxDp4a0AvNp7wuBQCApEYARNK4ce08ledn6XsvH/a6FAAAkhoBEEkjO8Ov2y9ZqGf2tOpo56DX5QAAkLQIgEgqH964UCbp39gSBgCAGSMAIqnML8nVe9bM0yOvHtHQaNDrcgAASEoEQCSdj1+5RN2DAT2+lS1hAACYCQIgks7Fi0u1rrZY333hIFvCAAAwAwRAJB0z011XLtGB9gE9t7fN63IAAEg6BEAkpZvW1qimOEff+e1Br0sBACDpEACRlDL9Pn308sV6aX+Hdh7v8bocAACSCgEQSeu2SxYqL8vPKCAAANNEAETSKs7N1G0XL9STbxzXsS42hgYAIFoEQCS1T75jiXwmffv5A16XAgBA0iAAIqnVFOfq/RsW6JFXj+pU/4jX5QAAkBQIgEh6n37nMo0GQ/rXF1kLCABANAiASHrLKgt0w3nz9L2XD6tvOOB1OQAAJDwCIFLCH169XH3DY/rey4e9LgUAgIRHAERKWFtbrGtWVuo7vz2g/pExr8sBACChEQCRMj777hXqGgzoey8f8roUAAASGgEQKWN9XYmuWVmpB55nFBAAgLMhACKlfPbdK9Q9GNDDLx3yuhQAABIWARApZX1did61qkrfZi0gAABnRABEyvncu+vVPRjQd37L6SAAAEyFAIiUs662RDeeP0/ffv6AOjgdBACAtyEAIiX96XtWaigQ1P3P7ve6FAAAEg4BEClpeVWBPnhRnX7wymEd6xr0uhwAABIKARAp63PX1Usm3ffLfV6XAgBAQiEAImXVFOfqo5cv1uNbj2nX8V6vywEAIGEQAJHSPnP1cpXkZupvf7pLzjmvywEAICEQAJHSivMy9bl3r9BL+zv0zO42r8sBACAhEACR8j68caGWVebr757ardGxkNflAADgOQIgUl6m36e/vHm1Dpwa0A9eOex1OQAAeI4AiLRwzcoqXVVfoX/81V42hwYApD0CINKCmen//d01GhwN6ss/3+N1OQAAeIoAiLSxvKpQH79yiR7dckxbj3R5XQ4AAJ4hACKt/PG19aouytYXn9ipYIhtYQAA6YkAiLRSkJ2hL9y0Wo0tPfrh5iNelwMAgCcIgEg7771gvi5bWq4v/3yP2nqHvS4HAIA5RwBE2jEzfen952tkLKT//d+7vC4HAIA5RwBEWlpaWaA/uma5frr9hJ7dwwkhAID0QgBE2vr0O5epvqpAf/WfOzQwMuZ1OQAAzBkCINJWVoZPf/+BtWrpHtJXnm7yuhwAAOYMARBp7aJFZfro5Yv18MuHtPlgp9flAAAwJwiASHt/fsNK1ZXm6c8fe0NDo0GvywEAIO4IgEh7eVkZ+vIH1ulQx6D+7y+YCgYApD4CICDpsmXl+oPLFunBFw9q04EOr8sBACCuCIBAxF/csEqLyvL0+UffUO9wwOtyAACIGwIgEJGfnaGvfWi9TvYO66+f3Ol1OQAAxA0BEJjgwoWluvua5Xr89RY91XjC63IAAIgLAiAwyd3vWq4L6kp07+ONauke8rocAABijgAITJLp9+nrt61XKOR097+/rtGxkNclAQAQUwRAYAqLyvP15VvXaeuRbv3Dz/d4XQ4AADFFAATO4Ka1NbrzskX6zgsH9YudJ70uBwCAmIlrADSzG8ysycyazeyeKV7PNrMfRV7fZGaLJ7x2b+R6k5ldf65nmtlDZnbQzLZFvtbH87MhPXzh5tVaV1usP/vxGzraOeh1OQAAxETcAqCZ+SXdL+lGSWsk3W5maybddpekLufcckn3Sfpy5L1rJN0m6TxJN0j6hpn5o3jm/3LOrY98bYvXZ0P6yM7w6/4PXygnsR4QAJAy4jkCeImkZufcAefcqKRHJN0y6Z5bJD0c+f4xSdeamUWuP+KcG3HOHZTUHHleNM8EYqquLE9fufUCvXGsR3/31G6vywEAYNbiGQAXSDo64edjkWtT3uOcG5PUI6n8LO891zO/ZGbbzew+M8uOxYcAJOmG8+fpY1cs1kMvHdJPt7M/IAAguaVSE8i9klZJulhSmaS/mOomM/uUmW0xsy3t7e1zWR+S3L03rtaGhSX6sx+/oR0tPV6XAwDAjMUzALZIqpvwc23k2pT3mFmGpGJJHWd57xmf6Zw74cJGJP2rwtPFb+Oce8A51+Cca6isrJzhR0M6ysrw6Vt3XKTSvEx98ntb1NY77HVJAADMSDwD4KuS6s1siZllKdzU8eSke56UdGfk+1sl/do55yLXb4t0CS+RVC9p89meaWY1kX9N0vsk7YjjZ0OaqirM0bfvbFD3YECf/P5rGg4EvS4JAIBpi1sAjKzpu1vS05J2S3rUObfTzP7GzN4bue27ksrNrFnS5yXdE3nvTkmPStol6eeSPuOcC57pmZFn/ZuZNUpqlFQh6W/j9dmQ3s6bX6z7PrRebxzt1p8/tl3h/2YBACB5WDr/j1dDQ4PbsmWL12UgSd3/bLO+8nST/vS6Ffqja+u9LgcAkOLM7DXnXEMsnpURi4cA6egPr16m5rZ+ffWXe7W8qkA3rq3xuiQAAKKSSl3AwJwyM/2f/7FWGxaW6E8e3abXDnd5XRIAAFEhAAKzkJPp1wN3NKi6KEcff+hVNZ3s87okAADOiQAIzFJlYbZ+cNdG5WT6dMd3N+lIB2cGAwASGwEQiIG6sjx97+MbNTIW0h0PblJbH3sEAgASFwEQiJGV8wr1rx+7WO19I/qD725Wz1DA65IAAJgSARCIoQsXlupbd1yk/e39uuuhVzU0ykbRAIDEQwAEYuyq+kr944c26LUjXfrU97cQAgEACYcACMTBzetq9A8fWKcXmk/p4w+9qsHRMa9LAgDgNAIgECcfbKjT137vAm062KE7H9ysvmHWBAIAEgMBEIij92+o1ddv36DXj3TrDhpDAAAJggAIxNnvrJuvb/z+hdp5vEe//51X1DUw6nVJAIA0RwAE5sD1583TA3c0aG9rv27/9ivsEwgA8BQBEJgj16yq0nfvbNDhjkH9j2+8pOa2fq9LAgCkKQIgMIeuqq/UI5+6VMOBoD7wzZe0+WCn1yUBANIQARCYYxfUleg//vAKlRdk6SPf3aT/3n7c65IAAGmGAAh4oK4sTz/5n5frgtpi3f3vW/XA8/vlnPO6LABAmiAAAh4pzc/S9+/aqJvX1ejvntqjLz6xU4FgyOuyAABpIMPrAoB0lpPp1/932wbVluTqW88fUFNrn+7/8IWqLMz2ujQAQApjBBDwmM9nuvem1frHD63X9mPdeu8/v6A3jnZ7XRYAIIURAIEE8b4NC/ST/+dy+X2mD37rZT366lGvSwIApCgCIJBAzptfrP+6+0pdsrhMf/6T7fqr/2zU6BjrAgEAsUUABBJMaX6WHvrYxfr0O5fqB68c0Qf/5SUd7hjwuiwAQAohAAIJKMPv0703rta/fOQiHTw1oJu//oKe2NbidVkAgBRBAAQS2A3nz9PPPvcOrZpXqM8+sk1/9uM3NDAy5nVZAIAkRwAEEtyCklw98qlL9cfvWq6fvH5Mv/vPL2jn8R6vywIAJDECIJAEMvw+ff49K/Vvn9iogZExve/+F3X/s80aY+NoAMAMEACBJHL5sgr97LPv0HVrqvWVp5t067+8rP3t/V6XBQBIMgRAIMmU5Wfp/g9fqK/fvkGHOgZ00z/9Vt/57QGFQpwlDACIDgEQSEJmpvdeMF+/+Nw7dOXyCv3tT3frtm+/wnYxAICoEACBJFZVlKPv3Nmgr9y6TruP9+r6f3xe//Kb/awNBACcFQEQSHJmpg821OkXn3+Hrqqv1N//bI9uuf9FNR6jUxgAMDUCIJAiaopz9cAdF+lfPnKh2vtGdMv9L+hv/3uXBkfZNxAA8FYEQCCFmJluOL9Gv/z8O3XbJQv1nRcO6j33Pa9f7Wr1ujQAQAIhAAIpqDg3U3/3/rX68f+8TLmZfn3ie1v08YdepUkEACCJAAiktIsXl+mpz16lv7p5tTYd6NB19z2vr/1yr4YDQa9LAwB4iAAIpLhMv0+fuGqpfv1nV+vG8+fp68/s07u/9hv9clernGPvQABIRwRAIE1UF+Xon27boB9+8lLlZfn1SaaFASBtEQCBNHPZsnL99I/D08KvHurSdfc9r688vUf9I3QLA0C6IAACaej0tPCfvlM3r63R/c/u19VfeU4/3HxEQY6UA4CURwAE0lhVUY7u+9B6PfGZK7SkIk/3Pt6om7/+Wz2/t93r0gAAcUQABKAL6kr06Kcv0zd//0INjgb1Bw9u1kf/dbP2tvZ5XRoAIA4IgAAkhTeRvnFtjX75+XfoL29ardcOd+mGf3xef/kfjTrVP+J1eQCAGLJ03gaioaHBbdmyxesygITUOTCqrz+zT99/5bByMny668ol+sQ7lqooJ9Pr0gAgLZnZa865hpg8iwBIAATOZn97v776iyY91XhSxbmZ+vQ7l+qjly9WXlaG16UBQFohAMYIARCI3o6WHn31F016tqldFQXZuvuaZbp940JlZ/i9Lg0A0gIBMEYIgMD0bTnUqa883aRNBztVVZitT1y1RB/euEgF2YwIAkA8EQBjhAAIzIxzTi/t79A3nmvWi80dKs7N1J2XLdJHr1iisvwsr8sDgJREAIwRAiAwe9uOduubzzXr6Z2tysn06baLF+oPLlukpZUFXpcGACmFABgjBEAgdprb+vTN5w7oiW0tGgs5XVVfoY9cukjXrqpShp8dpwBgtgiAMUIABGKvrW9YP9p8VP+++YhO9AxrfnGOPrxxoX6voU5VRTlelwcASYsAGCMEQCB+xoIhPbOnTT945bB+u++UfCZdsbxC79+wQNefN0/5NI0AwLQQAGOEAAjMjYOnBvQfrx/Tf2xr0dHOIeVm+vWe86r1vg0LdMWyCmVlMEUMAOdCAIwRAiAwt5xzeu1wlx7f2qKfbj+hnqGACnMydO2qKl1/3jy9c2UlG0wDwBkQAGOEAAh4Z2QsqOf3ntLTO0/qV7tb1T0YUHaGT1fVV+o9a6r1zpWVqmbNIACcFssAyH9qA/BEdoZf162p1nVrqjUWDGnzoU79Ymfr6UAoSatrinT1ykpdvaJSFy4qVSbdxAAQE4wAMgIIJBTnnHaf6NNze9v0XFO7Xj/cpbGQU2F2hq6sr9DVKyv1jhWVqinO9bpUAJhTTAHHCAEQSHy9wwG91HxKzzW167mmdp3sHZYkLavM1xXLK3T5snJdtrRCxXmZHlcKAPFFAIwRAiCQXJxz2tvar+f3tuvF/ae0+WCnBkeDMpPOn1+sy5eX64plFbp4cZlys/xelwsAMUUAjBECIJDcRsdCeuNYt15sPqWXmju09WiXAkGnLL9P62qL1bC4TA2LSnXRolKVckYxgCRHAIwRAiCQWgZHx/TqoS691HxKmw91akdLjwLB8P+Pq68qUMPiMl28uFQNi8pUV5YrM/O4YgCIHgEwRgiAQGobDgT1xtFubTncpVcPdeq1Q13qGxmTJFUUZGtdbbHOX1CstQuKta62mG1nACQ0toEBgCjkZPq1cWm5Ni4tlyQFQ057W/u05VCnth7pVmNLj55ralMo8t/BlYXZWjWvUPVVhaqvLlB9VYHqqwppMAGQcgiAANKG32daXVOk1TVFuuOy8LXB0THtOt6rxpYeNbb0aF9rv364+YiGAsHT76sqzI4EwkItq8xXXVmeFpblqbY0j2PsACQlAiCAtJaXlRFuFllcdvpaKOTU0j2kfW192tfar31t/drX2qdHtxzV4OibwdBMml+cq7qyXC2MhMK6sjwtKs/XwrI8leZlss4QQEIiAALAJD6fqS4S5t61qvr09VDIqb1/REc6B3WkYzD8b+Tr2aZ2tfeNvOU5BdkZWliWp0XleVpYnqdFZfnh78vyNL8kV34f4RCANwiAABAln89UXZSj6qIcXTxhxHDc4OiYjnYOvRkMOwZ0uHNQTSf79Kvdrac7kiUp02+qLc3Tssp81VcXqr6qQCuqC7WssoA9DAHEHQEQAGIkLytDK+cVauW8wre9Fgw5negZOj16eLhzUIc7BtTc1q/nmto1FulEMZPqSvO0orpAy6sKtbqmUOfNL9bSinz5GDEEECMEQACYA35feMSvtjRPly9762uBYEiHTg1oX1u/9rb2nV5z+Ju97adHDfOz/DpvfrHOW1CktZGta5ZWFjCNDGBG2AeQfQABJKhAMKTmtn41tvRoZ6RLedeJXg0HQpKk3Ey/1swv0rraYl1QW6J1tcVaXM5IIZCq2Ag6RgiAAJLNWDCkA6cG1HisRzuO95z+dzwUFuZkaF1tsdbVlmjdgmKtqyvR/OIcupGBFEAAjBECIIBUMBYMaV9bv7Yf69b2Yz3afqxHe072np4+rijICgfCCSOF5QXZHlcNYLo4CQQAcFqG33d6g+sPXRy+NhwIas/JPm0/1q03jvZo+7FuPdvUpvH/5l9QkqsL6sIjhefPL9bKeYWqLCQUAumCAAgAKSgn06/1dSVaX1ciRU496R8Z046WcBh841j436caT55+T3l+1uku5lXzCrVyXpFWVBcoL4v/qQBSDf9XDQBpoiA7Q5cuLdelkbORJalzYFS7T/Rqz8k+NZ3sVdPJPj2y+ejpo/DGt6VZUpGvJRX5Wlyep0UV+fr/27vX2MjOu47j3//MmYvt9W2v2d0EdsOmlVJe0NSqIvXygkJugm65iC5CNJRIFVIrqBCCVJFQhXhBQIBAVI0KDSRV6RZoq+4blKRQwau0cdJtskm7zSbZkr3Ee7U9a3s8tz8vzjP22Dvj1JbHY/v5faTRec5zzjw+569nzvn7OefMHN41wK2jfSRZ/RSeyFakBFBEJGI7B/K878hu3ndk90Jdo+H837VZTk+UOP1WidMTJc5emWH87DVmWn4KL8kYt472cWj3ALeN9rN/pMjBkT4OjPSxfzj9wuycEkSRTUkJoIiILJHJGId2D3Bo9wD3vuuWhXp358qNCj++OsMbV2Y4e3WGs1dnOXtlhpNvTjI5W13ajsG+oSL7h4scCInhgeEitwz3sW+owL6hInsGC0oSRXpACaCIiPxEzIw9gwX2DBYY6/BTeBcmy1yYnFt8TaXzp85P8fQrE1RqjWVtpvce7h0sLiSFe4dCebAYfnqvwK4dBX3ptcg6UgIoIiLroj+fcGTvDo7s3dF2eXMEcWK6zMR0mUul+VCe59J0mYlSmVMXprlyY57l31CWMdgzGBLEwQI7B/KM9ucZ6c8z2p9bmI4O5BnpzzHSlyefaGRRpBMlgCIisiFaRxB/9uBwx/Vq9caSRHGiFBLEkCyeuz7Hi+emmJytUqk3ewOj3QAAC6BJREFUOrZTSDIMFnMMFRMGi0la7ksYLOSWzheb8wlDxRxDLfN6yEW2KyWAIiKyqSTZDLcMF7lluLjieu7OXLXO9dkq12cqTM5WuT5bYXKuytRshVK5xnS5RqlcDeUqb02XF+ZnWx5o6aQvl00Tw77FpHExUUxuqls+v6OY6NK1bEpKAEVEZEsyM/rzCf35hIMjfat+f7Xe4Ea5tpActk5LLdPpuRql+XR+aq7KuWuzC4nlfK3zCGTTjkKyMKK4OCJ58yjkcF/6GmlO+3MMFnNKIKUrlACKiEiUctkMowN5Rgfya26jUmukSeLypLFcY3quOd+sS+ev3KjwxpWZhYSz+ZN9nQwVE4b7m8lhPk0U+29OFoeay8OygXxWvwEtHSkBFBERWaN8kmHXjsKaf1vZ3ZmvNZguV5meqzI1V2Vydul0aqG+wtRclQtTc0yH5bVG5+QxY83Rx9ySEcjW8o5CctOIZHPEUpewtzclgCIiIj1iZhRzWYq5LHsHV77ncTl3Z7ZSX5YsVhYSxtKyy9s3yjUulcq8dnlxVPLtRh8B+vPZtsnhYDFZkmDuKC4mk4uXvdNlhSSj0chNRgmgiIjIFmRmDBQSBgoJB9ZwD2Rz9HHpPY81bsw3L2mn9c37JJv3QZbKNS5MznFjvvYTP0yTy6b3aw7ks/TlswwUEvpy6bQ/nw2vxXI+yZDLZkiyGfJZI8lkSLJGPtTlspYuzxhJmGYzRpK1UG6pyxiZjLXMZ5bUx0oJoIiISIRaRx/3DK7tEjakX9szM19f8gBNMzkslauUQnmuUmdmPk0YZys1Zip1LpfmmaksXbbSZe31ZsaSxDDJGoUkk8YlyVLIZRanIVbp8rQ+rctQSMI0rFNM0nIhJLLNaZrYGvkkQ35hPk1WN3qEVAmgiIiIrFmSzTDcn2G4P7cu7VVqDar15sup1hvU6k6l3qDWaFCtOdVGg2qtQa3h1BpOvZGuU1+Yb6lvzrcsb3hzvrFk/Wq9wXy1QblWp1ytM19rUK7WKZVrXC7NL8w3p+VqnfXIV83Sh5IK2Qy5JE0I0xFQWyiv908mdjUBNLP7gL8DssA/uftfLFteAJ4E3gNcBT7q7mfDss8ADwF14Pfd/amV2jSzw8BxYBfwPPDb7l7p5v6JiIjI+sonmS3zKy7uTrXulGv1NHGs1pmv1SmHcqXWoFJvhKTWqdTrVGveUrc4na83wrI6tXrabi0kttV6Y91HRruWAJpZFvgc8IvAOeA5Mzvh7q+0rPYQcN3dj5jZMeBR4KNmdidwDHgXcAD4lpm9I7ynU5uPAn/r7sfN7LHQ9ue7tX8iIiISNzMjn6SXdFndMzxr8s8fX7+2uplivxc44+6vh5G448DRZescBZ4I5f8APmTpRfCjwHF3n3f3N4Azob22bYb3/Hxog9DmR7q4byIiIiJbVjcTwIPAmy3z50Jd23XcvQZMkV7C7fTeTvW7gMnQRqe/JSIiIiJ0NwHclMzsE2Y2bmbjly9f7vXmiIiIiGy4biaA54HbWuZvDXVt1zGzBBgmfRik03s71V8FRkIbnf4WAO7+BXcfc/exPXv2rGG3RERERLa2biaAzwF3mNlhM8uTPtRxYtk6J4AHQ/nXgf92dw/1x8ysEJ7uvQP4bqc2w3u+HdogtPnNLu6biIiIyJbVtaeA3b1mZp8CniL9ypbH3f1lM/szYNzdTwBfBL5kZmeAa6QJHWG9fwNeAWrAJ929DtCuzfAn/wQ4bmZ/DnwvtC0iIiIiy1g6eBansbExHx8f7/VmiIiIiLwtM3ve3cfWo63oHgIRERERiZ0SQBEREZHIKAEUERERiYwSQBEREZHIKAEUERERiYwSQBEREZHIKAEUERERiYwSQBEREZHIKAEUERERiYwSQBEREZHIKAEUERERiYwSQBEREZHIKAEUERERiYwSQBEREZHIKAEUERERiYwSQBEREZHIKAEUERERiYwSQBEREZHIKAEUERERiYwSQBEREZHImLv3eht6xsxKwOleb8cmtBu40uuN2GQUk/YUl/YUl/YUl5spJu0pLu29090H16OhZD0a2cJOu/tYrzdiszGzccVlKcWkPcWlPcWlPcXlZopJe4pLe2Y2vl5t6RKwiIiISGSUAIqIiIhEJvYE8Au93oBNSnG5mWLSnuLSnuLSnuJyM8WkPcWlvXWLS9QPgYiIiIjEKPYRQBEREZHoRJkAmtl9ZnbazM6Y2cO93p6NZGa3mdm3zewVM3vZzP4g1H/WzM6b2cnweqDlPZ8JsTptZvf2buu7y8zOmtlLYf/HQ91OM3vGzF4N09FQb2b29yEuL5rZXb3d+u4ws3e29ImTZjZtZp+Osb+Y2eNmdsnMTrXUrbp/mNmDYf1XzezBXuzLeukQk78ysx+G/f6GmY2E+kNmNtfSZx5rec97wmfvTIib9WJ/1kuHuKz6M7PdzlUd4vLVlpicNbOToT6K/rLCObn7xxZ3j+oFZIHXgNuBPPB94M5eb9cG7v9+4K5QHgR+BNwJfBb4ozbr3xliVAAOh9hle70fXYrNWWD3srq/BB4O5YeBR0P5AeA/AQPuBr7T6+3fgPhkgbeAn46xvwAfBO4CTq21fwA7gdfDdDSUR3u9b+sck3uAJJQfbYnJodb1lrXz3RAnC3G7v9f71oW4rOozsx3PVe3ismz5XwN/GlN/WeGc3PVjS4wjgO8Fzrj76+5eAY4DR3u8TRvG3S+6+wuhXAJ+ABxc4S1HgePuPu/ubwBnSGMYi6PAE6H8BPCRlvonPfUsMGJm+3uxgRvoQ8Br7v7jFdbZtv3F3f8XuLaserX9417gGXe/5u7XgWeA+7q/9d3RLibu/rS718Lss8CtK7UR4jLk7s96eiZ7ksU4bkkd+konnT4z2+5ctVJcwijebwBfWamN7dZfVjgnd/3YEmMCeBB4s2X+HCsnQNuWmR0C3g18J1R9KgwpP94cbiaueDnwtJk9b2afCHX73P1iKL8F7AvlmOLSdIylB+fY+wusvn/EFp/fJR2taDpsZt8zs/8xsw+EuoOkcWjazjFZzWcmtr7yAWDC3V9tqYuqvyw7J3f92BJjAiiAme0AvgZ82t2ngc8DPwP8HHCRdCg+Nu9397uA+4FPmtkHWxeG/zajfGzezPLAh4F/D1XqL8vE3D/aMbNHgBrw5VB1Efgpd3838IfAv5rZUK+2rwf0mVnZb7L0H8yo+kubc/KCbh1bYkwAzwO3tczfGuqiYWY50o72ZXf/OoC7T7h73d0bwD+yeNkumni5+/kwvQR8gzQGE81Lu2F6KaweTVyC+4EX3H0C1F9arLZ/RBEfM/sd4JeA3wonL8Ilzquh/Dzp/W3vIN3/1svE2zIma/jMRNFXAMwsAX4V+GqzLqb+0u6czAYcW2JMAJ8D7jCzw2FU4xhwosfbtGHCfRZfBH7g7n/TUt96/9qvAM2ntE4Ax8ysYGaHgTtIb8DdVsxswMwGm2XSG9lPke5/82mqB4FvhvIJ4GPhiay7gamW4frtaMl/57H3lxar7R9PAfeY2Wi4BHhPqNs2zOw+4I+BD7v7bEv9HjPLhvLtpH3j9RCXaTO7OxyfPsZiHLeNNXxmYjpX/QLwQ3dfuLQbS3/pdE5mI44t3Xy6ZbO+SJ+i+RHpfxSP9Hp7Nnjf3086lPwicDK8HgC+BLwU6k8A+1ve80iI1Wm28NNWbxOX20mfsvs+8HKzXwC7gP8CXgW+BewM9QZ8LsTlJWCs1/vQxdgMAFeB4Za66PoLaQJ8EaiS3l/z0Fr6B+l9cWfC6+O93q8uxOQM6b1IzePLY2HdXwufrZPAC8Avt7QzRpoQvQb8A+FHCrbqq0NcVv2Z2W7nqnZxCfX/AvzesnWj6C90Pid3/diiXwIRERERiUyMl4BFREREoqYEUERERCQySgBFREREIqMEUERERCQySgBFREREIqMEUERERCQySgBFREREIqMEUERERCQy/w+KQCbaVZ8ZuwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJo_-P09Tl8i"
      },
      "source": [
        "# Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgjXc1MdSzj9"
      },
      "source": [
        "from transformers import BertTokenizer"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "6f2391eedd6640c7b317d8a1a74e6761",
            "e5179e33a8cb4729b5883b94a516a8ba",
            "53b36bade9f3479cb238d708ca78c946",
            "dd102d14513f447aa0c8d35523172d29",
            "c547dbec0d234742a87609b7aa2c0132",
            "df9e07463b834312bcb72d71b9f8276f",
            "acba4621d88b4174b790e1f1d7838579",
            "c1c031064dc34858b662192d32453961"
          ]
        },
        "id": "A3QmjCunT24q",
        "outputId": "f51357d2-31f4-4b67-8467-08dbfaf8c7f4"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f2391eedd6640c7b317d8a1a74e6761",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeVywdDxUBCC",
        "outputId": "6038036a-3d1a-4400-e008-83c2d186d94c"
      },
      "source": [
        "sentence = df.comment_text.iloc[0]\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(f'Sentence:{sentence}')\n",
        "print(f'Tokens:{tokens}')\n",
        "print(f'Token_ids:{token_ids}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence:Explanation\n",
            "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
            "Tokens:['Ex', '##p', '##lana', '##tion', 'Why', 'the', 'edit', '##s', 'made', 'under', 'my', 'user', '##name', 'Hard', '##core', 'Metal', '##lica', 'Fan', 'were', 'reverted', '?', 'They', 'weren', \"'\", 't', 'van', '##dal', '##isms', ',', 'just', 'closure', 'on', 'some', 'GA', '##s', 'after', 'I', 'voted', 'at', 'New', 'York', 'Doll', '##s', 'FA', '##C', '.', 'And', 'please', 'don', \"'\", 't', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'I', \"'\", 'm', 'retired', 'now', '.', '89', '.', '205', '.', '38', '.', '27']\n",
            "Token_ids:[16409, 1643, 20592, 2116, 2009, 1103, 14609, 1116, 1189, 1223, 1139, 4795, 16124, 9322, 9475, 9953, 9538, 16061, 1127, 17464, 136, 1220, 3920, 112, 189, 3498, 6919, 16762, 117, 1198, 8354, 1113, 1199, 20173, 1116, 1170, 146, 4751, 1120, 1203, 1365, 25137, 1116, 6820, 1658, 119, 1262, 4268, 1274, 112, 189, 5782, 1103, 27821, 1121, 1103, 2037, 3674, 1290, 146, 112, 182, 2623, 1208, 119, 5840, 119, 17342, 119, 3383, 119, 1765]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLJBXufhU7Xy"
      },
      "source": [
        "assert len(tokens) == len(token_ids)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpEMhfzTVOqO"
      },
      "source": [
        "# Special Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v1oXEfNVMEF",
        "outputId": "0631076f-5eb7-4eb3-d6d2-b6e898610cad"
      },
      "source": [
        "print(tokenizer.sep_token,tokenizer.sep_token_id)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[SEP] 102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-pILafJVR0i",
        "outputId": "da941e6d-46a4-4861-ac4f-29ee2540cf96"
      },
      "source": [
        "print(tokenizer.cls_token,tokenizer.cls_token_id)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] 101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cBx0NLlVkDO",
        "outputId": "24e636f9-03b7-448f-9bf8-ad6d92929841"
      },
      "source": [
        "print(tokenizer.pad_token,tokenizer.pad_token_id)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PAD] 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sXZc5jlVmSp",
        "outputId": "223d7723-5811-4fad-fd99-f221640ed7a1"
      },
      "source": [
        "print(tokenizer.unk_token,tokenizer.unk_token_id)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[UNK] 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB11OYKpVsMi"
      },
      "source": [
        "enc = tokenizer.encode_plus(df.comment_text.iloc[18],\n",
        "                      max_length = 128,\n",
        "                      truncation = True,\n",
        "                      add_special_tokens = True,  ##[CLS] +[SEP]\n",
        "                      return_token_type_ids = False,\n",
        "                      return_attention_mask = True,\n",
        "                      return_tensors = 'pt')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07vaL5ruYdKl",
        "outputId": "5250cc28-e32d-430b-bf29-38907f4c90b6"
      },
      "source": [
        "\n",
        "vars(enc)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'_encodings': None,\n",
              " '_n_sequences': None,\n",
              " 'data': {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "           1, 1, 1, 1, 1, 1, 1, 1]]),\n",
              "  'input_ids': tensor([[  101,  1109, 12107,  9552, 27744,  1182,  1553,  1189,  1185,  2305,\n",
              "             118,  1725,  1136,  6982,  1106,  1511,  9001,  1113,   155,  7490,\n",
              "           17784,  1968, 21150,   112,   188,  3674,  1106,  1511,  1167,  1869,\n",
              "             136,   102]])}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vYm98VUY7vi",
        "outputId": "3b5175fe-4e98-42a9-8b8c-b6a67e150c5a"
      },
      "source": [
        "print(len(enc[\"attention_mask\"][0]),len(enc[\"input_ids\"][0]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlIvOtsWYH0M",
        "outputId": "795a07a2-4c55-4b2a-abd4-c3f81bada28e"
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(enc['input_ids'][0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'The',\n",
              " 'Mi',\n",
              " '##tsu',\n",
              " '##rug',\n",
              " '##i',\n",
              " 'point',\n",
              " 'made',\n",
              " 'no',\n",
              " 'sense',\n",
              " '-',\n",
              " 'why',\n",
              " 'not',\n",
              " 'argue',\n",
              " 'to',\n",
              " 'include',\n",
              " 'Hindi',\n",
              " 'on',\n",
              " 'R',\n",
              " '##yo',\n",
              " 'Sa',\n",
              " '##ka',\n",
              " '##zaki',\n",
              " \"'\",\n",
              " 's',\n",
              " 'page',\n",
              " 'to',\n",
              " 'include',\n",
              " 'more',\n",
              " 'information',\n",
              " '?',\n",
              " '[SEP]']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXxhnP50Z1vj"
      },
      "source": [
        "# Create Custom Pytorch DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK8SXENrZ40w"
      },
      "source": [
        "class ToxicDataset(Dataset):\n",
        "  def __init__(self,comment,target,tokenizer,max_len):\n",
        "    self.comment = comment\n",
        "    self.target = target\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.comment)\n",
        "\n",
        "  def __getitem__(self,item):\n",
        "    comment = str(self.comment[item])\n",
        "    target  = self.target[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(comment,\n",
        "                      max_length = 128,\n",
        "                      truncation = True,\n",
        "                      add_special_tokens = True,  ##[CLS] +[SEP]\n",
        "                      return_token_type_ids = False,\n",
        "                      return_attention_mask = True,\n",
        "                      pad_to_max_length = True,\n",
        "                      return_tensors = 'pt')\n",
        "    #print(len(encoding[\"attention_mask\"][0]),len(encoding[\"input_ids\"][0]))\n",
        "    return {\n",
        "        \"comment_text\":comment,\n",
        "        \"input_ids\":encoding[\"input_ids\"].flatten(),\n",
        "        \"attention_mask\":encoding[\"attention_mask\"].flatten(),\n",
        "        \"targets\":torch.tensor(target,dtype = torch.long)\n",
        "    }"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXfAf0cebUvs"
      },
      "source": [
        "df_train,df_test  = train_test_split(df,test_size = 0.2,random_state=123)\n",
        "df_val,df_test  = train_test_split(df_test,test_size = 0.5,random_state=123)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC_RvVKvbi0a",
        "outputId": "1a8e00a8-8dbf-4621-d706-e50cc3368754"
      },
      "source": [
        "\n",
        "df_train.shape,df_val.shape,df_test.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((127656, 8), (15957, 8), (15958, 8))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apec1kz3bsx8"
      },
      "source": [
        "# Create DataLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oc6hJ4Bbvia"
      },
      "source": [
        "def comment_data_loader(df,tokenizer,max_len,batch_size):\n",
        "  toxic_dataset = ToxicDataset(comment = df.comment_text.to_numpy(),\n",
        "                               target = df.toxic.to_numpy(),\n",
        "                               tokenizer = tokenizer,\n",
        "                               max_len = max_len)\n",
        "  \n",
        "  return DataLoader(toxic_dataset,batch_size=batch_size,num_workers=4)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O60rvl0dcbQh"
      },
      "source": [
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 2\n",
        "train_data_loader = comment_data_loader(df_train,tokenizer,MAX_LEN,BATCH_SIZE)\n",
        "val_data_loader = comment_data_loader(df_val,tokenizer,MAX_LEN,BATCH_SIZE)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MuGilehxZxHR",
        "outputId": "696561f3-2251-4397-aa83-6fa46c24356a"
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['comment_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RzVn14Ki6YK",
        "outputId": "ecd2a9f2-2ad6-4de0-f1cb-94cea677ed54"
      },
      "source": [
        "print(data[\"comment_text\"])\n",
        "print(data[\"input_ids\"])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"I know my comment was wrong, but what I'm trying to say is that he is stalking my edits! Even if I make a comment on the natural wildlife in north Punjab province, he's theres.\", '\"\\nErgo, it\\'s neither the flag of the PA nor of the \"\"Palestinian Territories\"\" (whatever that means), but of a now-defunct British protectorate, and therefor belongs un nneither infobox. What\\'s your point again? And where are your reliable sources backing it up? 24.177.122.31  \"']\n",
            "tensor([[  101,   146,  1221,  1139,  7368,  1108,  2488,   117,  1133,  1184,\n",
            "           146,   112,   182,  1774,  1106,  1474,  1110,  1115,  1119,  1110,\n",
            "         23281,  1139, 14609,  1116,   106,  2431,  1191,   146,  1294,   170,\n",
            "          7368,  1113,  1103,  2379, 10501,  1107,  1564,  8907,  3199,   117,\n",
            "          1119,   112,   188,  1175,  1116,   119,   102,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   107,   142, 17161,   117,  1122,   112,   188,  4534,  1103,\n",
            "          5167,  1104,  1103,  8544,  4040,  1104,  1103,   107,   107,  8988,\n",
            "         18057,   107,   107,   113,  3451,  1115,  2086,   114,   117,  1133,\n",
            "          1104,   170,  1208,   118, 12273,  1418, 23476,  2193,   117,  1105,\n",
            "          1175, 14467,  1197,  7017,  8362,   183,  1673,  7088,  1200, 23992,\n",
            "          8757,   119,  1327,   112,   188,  1240,  1553,  1254,   136,  1262,\n",
            "          1187,  1132,  1240, 10682,  3509,  4581,  1122,  1146,   136,  1572,\n",
            "           119, 19478,   119, 13381,   119,  1955,   107,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAU3myJRseGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09328c1d-b127-44dc-de53-0be0dfd099a8"
      },
      "source": [
        "print(data[\"input_ids\"].shape)\n",
        "print(data[\"attention_mask\"].shape)\n",
        "print(data[\"targets\"].shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 128])\n",
            "torch.Size([2, 128])\n",
            "torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg732gXCwy2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5923c5c-0427-46eb-f51b-818257c8d7ac"
      },
      "source": [
        "data[\"input_ids\"]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,   146,  1221,  1139,  7368,  1108,  2488,   117,  1133,  1184,\n",
              "           146,   112,   182,  1774,  1106,  1474,  1110,  1115,  1119,  1110,\n",
              "         23281,  1139, 14609,  1116,   106,  2431,  1191,   146,  1294,   170,\n",
              "          7368,  1113,  1103,  2379, 10501,  1107,  1564,  8907,  3199,   117,\n",
              "          1119,   112,   188,  1175,  1116,   119,   102,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0],\n",
              "        [  101,   107,   142, 17161,   117,  1122,   112,   188,  4534,  1103,\n",
              "          5167,  1104,  1103,  8544,  4040,  1104,  1103,   107,   107,  8988,\n",
              "         18057,   107,   107,   113,  3451,  1115,  2086,   114,   117,  1133,\n",
              "          1104,   170,  1208,   118, 12273,  1418, 23476,  2193,   117,  1105,\n",
              "          1175, 14467,  1197,  7017,  8362,   183,  1673,  7088,  1200, 23992,\n",
              "          8757,   119,  1327,   112,   188,  1240,  1553,  1254,   136,  1262,\n",
              "          1187,  1132,  1240, 10682,  3509,  4581,  1122,  1146,   136,  1572,\n",
              "           119, 19478,   119, 13381,   119,  1955,   107,   102,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w31tjmvLtH3V"
      },
      "source": [
        "# Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yt2WfmqtHDv"
      },
      "source": [
        "from transformers import BertModel"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_vATywlth00",
        "outputId": "7d7875d2-3dab-4dd0-dfc8-04749806815f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "f61fbaadb162415c9dff85ea180e136f",
            "997186c85f604e71b835ee9ccecdeffb",
            "cf28ffa1d0ac449aa78143248a5f8bbe",
            "630ecf88f0854a0fa18a5008606c43d8",
            "fef2cfa269474a70b43d9aa7b44146e5",
            "18a0df8ccc2c49c991f9fd6edc47fc02",
            "9ac7a337a50e47a39714795c49238a8f",
            "67bbd5eec02a44348fb61046ef5bc5ff",
            "e2a93451fa5046fd95be05ab886d89e6",
            "c3313e12fb7b45b8b872f84b148c4620",
            "b03b59d41c4b4e07a7165a71df984fa0",
            "1027b7caf35343908bd5da991d6a52cd",
            "cadeb47a852549b79ac781c4f28c74c9",
            "90720ca28c66426593435d6e9c9651ab",
            "f0f071d5f4094950a89cc5b5e56638da",
            "c1295dc7e2984eaba00fccae5d130ef1"
          ]
        }
      },
      "source": [
        "PRETRAINED_MODEL_NAME = \"bert-base-cased\"\n",
        "bert_model = BertModel.from_pretrained(PRETRAINED_MODEL_NAME)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f61fbaadb162415c9dff85ea180e136f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e2a93451fa5046fd95be05ab886d89e6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqzg32tIxQMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069b7cab-8112-4dd5-e450-1192cb4c63ca"
      },
      "source": [
        "enc"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1109, 12107,  9552, 27744,  1182,  1553,  1189,  1185,  2305,\n",
              "           118,  1725,  1136,  6982,  1106,  1511,  9001,  1113,   155,  7490,\n",
              "         17784,  1968, 21150,   112,   188,  3674,  1106,  1511,  1167,  1869,\n",
              "           136,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pOIGm5dxxyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eacd13e6-973d-4c53-e161-0e9ee770adae"
      },
      "source": [
        "bert_model"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSsHmUdwwe_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ada0519-8f04-47ea-f7bb-1eaad384eee3"
      },
      "source": [
        "bert_model.config"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"bert-base-cased\",\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 512,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"vocab_size\": 28996\n",
              "}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNEhm968x6ZZ"
      },
      "source": [
        "output = bert_model(**enc)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaZo3JzqyVjz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f4f266-e6b7-440c-abe5-e939a6e81167"
      },
      "source": [
        "output"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BaseModelOutputWithPoolingAndCrossAttentions([('last_hidden_state',\n",
              "                                               tensor([[[ 0.6845, -0.0810,  0.0153,  ..., -0.2105, -0.0649, -0.2277],\n",
              "                                                        [ 0.0815, -0.4615,  0.4054,  ...,  0.5217, -0.1802,  0.1272],\n",
              "                                                        [ 0.1511, -0.0035,  0.7891,  ...,  0.2683, -0.5806, -0.3902],\n",
              "                                                        ...,\n",
              "                                                        [ 0.6177,  0.0620,  0.2881,  ...,  0.2093, -0.1116,  0.0328],\n",
              "                                                        [ 0.4378, -0.4630,  0.1347,  ...,  0.1306, -0.4123,  0.2538],\n",
              "                                                        [ 1.3969, -0.1733,  0.4659,  ..., -0.4534,  0.0131, -1.2319]]],\n",
              "                                                      grad_fn=<NativeLayerNormBackward>)),\n",
              "                                              ('pooler_output',\n",
              "                                               tensor([[-3.5902e-01,  2.9601e-01,  9.9836e-01, -9.7101e-01,  8.8210e-01,\n",
              "                                                         9.2907e-01,  9.1958e-01, -9.9843e-01, -8.7757e-01, -5.3338e-01,\n",
              "                                                         9.2329e-01,  9.9324e-01, -9.9977e-01, -9.9799e-01,  9.1250e-01,\n",
              "                                                        -8.8167e-01,  9.5796e-01, -3.2765e-01, -9.9954e-01, -8.3058e-01,\n",
              "                                                        -7.7830e-01, -9.9839e-01,  4.7862e-02,  9.9046e-01,  8.8565e-01,\n",
              "                                                         1.9350e-02,  9.4751e-01,  9.9959e-01,  7.9600e-01, -6.6510e-01,\n",
              "                                                         9.6512e-02, -9.6083e-01,  8.9507e-01, -9.9385e-01,  7.5071e-02,\n",
              "                                                         4.5780e-01,  8.6822e-01, -1.0689e-01,  8.5809e-01, -9.5546e-01,\n",
              "                                                        -3.6151e-01, -9.1630e-01,  8.1727e-01, -4.2096e-01,  9.5582e-01,\n",
              "                                                        -9.4938e-02, -1.0364e-01, -1.0258e-01,  1.0600e-01,  9.9254e-01,\n",
              "                                                        -8.2839e-01, -5.8436e-01, -9.9898e-01,  7.2941e-01,  9.7408e-01,\n",
              "                                                         9.5479e-02,  9.8395e-01,  4.3815e-02, -9.9978e-01, -3.3972e-01,\n",
              "                                                         8.8861e-01,  3.5754e-01,  7.2801e-01,  2.4490e-01,  5.1009e-01,\n",
              "                                                        -8.4115e-02, -9.5027e-01, -1.1457e-01, -3.9242e-01,  1.3216e-01,\n",
              "                                                        -5.7362e-02,  2.0104e-01,  8.9281e-01, -7.3581e-01,  7.6404e-02,\n",
              "                                                        -7.8171e-01, -2.3056e-01, -9.9858e-01,  9.2282e-01,  9.9951e-01,\n",
              "                                                         9.2416e-01, -9.9853e-01,  9.8043e-01, -9.4853e-02, -8.8869e-01,\n",
              "                                                         9.2430e-01, -9.9987e-01, -9.9670e-01, -3.4155e-02, -2.6500e-01,\n",
              "                                                         9.4536e-01, -9.5738e-01,  7.3002e-01, -9.6184e-01,  9.9964e-01,\n",
              "                                                        -9.5284e-01, -4.8703e-02,  1.6026e-01,  9.6535e-01, -8.9759e-01,\n",
              "                                                        -3.5927e-01,  9.7036e-01,  9.9988e-01, -9.9935e-01,  9.9970e-01,\n",
              "                                                         7.8819e-01, -8.9892e-01, -9.2174e-01,  9.2400e-01, -1.1347e-01,\n",
              "                                                         9.4135e-01, -9.1438e-01, -9.0675e-01, -2.0122e-01,  9.5291e-01,\n",
              "                                                        -9.5124e-01,  9.6207e-01,  9.1266e-01, -6.7315e-02,  9.9972e-01,\n",
              "                                                         2.3998e-02,  9.8384e-01,  9.9227e-01,  9.4624e-01, -9.4531e-01,\n",
              "                                                         2.0840e-03, -7.7655e-01,  9.4236e-01, -6.8723e-01,  3.8055e-02,\n",
              "                                                         5.9553e-01, -9.6973e-01, -9.9946e-01,  9.9689e-01, -1.4038e-01,\n",
              "                                                         9.9965e-01, -9.9434e-01,  9.9759e-01, -9.9919e-01, -9.3771e-01,\n",
              "                                                        -8.6761e-01,  9.3416e-03, -9.9441e-01, -3.5397e-01,  9.4598e-01,\n",
              "                                                        -1.1040e-01, -9.5111e-01, -8.9586e-01,  6.8230e-01, -9.3249e-01,\n",
              "                                                         2.8137e-01,  4.5633e-01, -7.9794e-01, -4.8660e-01,  9.9945e-01,\n",
              "                                                         9.6659e-01,  9.8499e-01,  3.8581e-02, -9.8648e-01,  9.4049e-01,\n",
              "                                                         9.3153e-01, -9.9700e-01,  9.4517e-01, -9.9859e-01,  9.9316e-01,\n",
              "                                                         8.7745e-01,  9.0052e-01, -9.9936e-01,  9.9926e-01, -8.0009e-01,\n",
              "                                                        -4.4871e-01,  5.3518e-01, -1.0585e-01, -9.9985e-01,  2.8359e-01,\n",
              "                                                         2.1124e-01,  4.0603e-01,  9.9263e-01, -9.7103e-01,  9.9135e-01,\n",
              "                                                        -8.3531e-01,  3.4408e-01,  4.7755e-01,  9.9981e-01, -9.8086e-01,\n",
              "                                                        -8.8023e-01, -9.4693e-01,  7.2243e-02,  9.1655e-01,  8.4614e-01,\n",
              "                                                         6.1752e-01,  8.5966e-01,  9.9976e-01,  3.0107e-01, -9.8530e-01,\n",
              "                                                        -1.9832e-01,  8.9080e-01,  5.9943e-02,  9.9970e-01, -5.1569e-01,\n",
              "                                                        -9.9851e-01, -8.6585e-01,  9.7217e-01,  8.6816e-01, -1.4027e-01,\n",
              "                                                         9.0042e-01, -8.5082e-01, -4.6003e-01,  9.9559e-01,  6.0621e-01,\n",
              "                                                         9.9979e-01,  4.4354e-01,  9.0441e-01,  7.5591e-01,  9.4943e-01,\n",
              "                                                        -9.4052e-01,  8.6539e-02,  6.2534e-02, -8.3549e-01,  9.9870e-01,\n",
              "                                                        -9.9706e-01, -6.9903e-02,  1.5056e-01, -9.7772e-01, -9.9191e-01,\n",
              "                                                         9.0475e-01,  1.8738e-01, -8.6018e-01,  2.1511e-02,  9.3639e-01,\n",
              "                                                         3.8357e-02,  9.6439e-01,  9.5916e-01, -8.0591e-01, -8.6737e-01,\n",
              "                                                        -9.9875e-01, -9.9970e-01, -6.9015e-01, -9.8716e-01, -1.1248e-01,\n",
              "                                                         5.6022e-01, -1.0964e-01, -7.5383e-01, -9.9980e-01,  8.6741e-01,\n",
              "                                                         9.2221e-01, -9.5084e-01,  2.7533e-02, -8.8630e-01, -9.9976e-01,\n",
              "                                                         8.3612e-01, -9.4686e-01, -9.9164e-01,  9.9667e-01, -9.2518e-01,\n",
              "                                                         9.9899e-01,  7.8749e-01, -9.7464e-01,  9.2139e-01, -9.9986e-01,\n",
              "                                                        -1.3620e-01,  3.4977e-01,  5.1043e-01,  8.5688e-01, -8.9815e-01,\n",
              "                                                         2.5309e-01,  9.7168e-01, -8.8827e-01, -8.4764e-01,  9.1471e-01,\n",
              "                                                        -9.9908e-01,  8.1748e-01, -6.0703e-03,  9.9643e-01,  9.6193e-01,\n",
              "                                                        -4.4650e-01,  9.1372e-01,  9.6114e-01, -9.5783e-01, -9.9836e-01,\n",
              "                                                         9.6415e-01, -8.1065e-01, -9.6902e-01,  3.9042e-02,  9.9942e-01,\n",
              "                                                        -9.9983e-01, -4.6542e-01, -8.7098e-01, -9.6079e-01, -9.9772e-01,\n",
              "                                                         4.6240e-01, -9.5233e-01,  3.5835e-01,  9.2665e-01,  5.8944e-01,\n",
              "                                                         3.3350e-01,  9.7238e-01,  4.1904e-01,  3.6262e-01, -4.7752e-01,\n",
              "                                                        -1.7852e-01, -9.4545e-01,  6.7645e-01,  8.4346e-01, -3.7240e-03,\n",
              "                                                        -9.9957e-01,  9.9865e-01, -9.6944e-01, -5.4098e-01,  9.5108e-01,\n",
              "                                                        -9.9953e-01,  7.2574e-01,  1.9726e-01, -9.8724e-01, -2.0448e-01,\n",
              "                                                         9.9909e-01,  9.2241e-01,  1.1761e-01, -5.0570e-02,  9.4195e-01,\n",
              "                                                        -4.2909e-01,  8.3546e-01, -9.4575e-01, -7.9733e-01, -9.5845e-02,\n",
              "                                                        -7.9717e-01,  9.9584e-01,  8.9618e-01, -9.5118e-01,  9.9883e-01,\n",
              "                                                        -1.6615e-01,  5.1437e-01, -9.0303e-01,  7.1653e-01,  9.5612e-01,\n",
              "                                                         1.8952e-01, -5.3382e-01,  1.4581e-01,  9.2850e-01, -9.9616e-01,\n",
              "                                                        -1.4745e-01, -9.9939e-01, -5.4370e-01,  9.7274e-01,  9.2804e-01,\n",
              "                                                        -9.3020e-01,  2.6629e-01,  5.0556e-03,  9.5460e-01, -9.9979e-01,\n",
              "                                                         9.9974e-01, -9.0833e-01, -4.2564e-02,  8.7311e-01, -9.5509e-01,\n",
              "                                                        -6.7805e-01,  9.7077e-01,  9.9667e-01,  9.9080e-01, -9.7464e-01,\n",
              "                                                        -8.7049e-01,  5.7337e-01,  8.0099e-01, -9.9151e-01, -9.6974e-03,\n",
              "                                                        -9.9994e-01, -8.1684e-01,  9.7899e-01,  9.9969e-01,  1.9426e-01,\n",
              "                                                         1.5608e-01, -9.9963e-01,  9.1491e-01, -9.5523e-01, -9.3751e-01,\n",
              "                                                         7.7298e-02, -8.9475e-01,  8.5266e-01,  9.9979e-01, -8.2121e-01,\n",
              "                                                         8.3315e-01,  4.8560e-02, -9.2576e-01,  9.3962e-01,  9.1267e-01,\n",
              "                                                         9.9900e-01, -9.1442e-01,  6.5092e-01,  9.5029e-01,  9.0199e-03,\n",
              "                                                        -8.0098e-01,  2.0339e-01,  9.9985e-01, -8.3208e-01, -3.7113e-02,\n",
              "                                                        -9.9767e-01, -6.9267e-03, -4.9413e-01, -4.5975e-01, -8.4649e-01,\n",
              "                                                        -4.8110e-02, -9.2638e-01,  9.8609e-01,  5.0139e-01,  5.3471e-01,\n",
              "                                                        -5.3367e-01,  9.3523e-01, -5.1704e-01,  1.2761e-01, -1.8759e-01,\n",
              "                                                        -5.3365e-01,  2.9813e-01,  4.3283e-01,  9.1924e-01, -8.4884e-01,\n",
              "                                                         9.9551e-01, -5.2690e-02, -9.9966e-01, -9.9963e-01, -9.1894e-01,\n",
              "                                                        -9.9409e-01,  8.5036e-01, -7.5987e-01,  9.5152e-01,  9.4551e-01,\n",
              "                                                        -9.9979e-01, -9.9991e-01, -8.3916e-01,  5.8290e-02,  9.3009e-01,\n",
              "                                                         8.1728e-01,  1.8099e-01,  6.1822e-01, -9.4139e-01, -6.4449e-02,\n",
              "                                                        -4.8519e-01,  7.3977e-02, -8.3303e-01, -7.6066e-01, -9.9983e-01,\n",
              "                                                         9.1402e-01, -9.9953e-01, -9.0210e-01,  9.9941e-01, -9.9929e-01,\n",
              "                                                        -9.7934e-01, -7.5118e-01, -9.1909e-01, -5.1418e-01,  1.2650e-01,\n",
              "                                                         9.2184e-01, -4.0613e-01, -8.5849e-01, -9.9253e-01,  9.3718e-01,\n",
              "                                                        -9.4460e-01, -1.2242e-02, -9.0082e-01, -8.9361e-01,  9.9716e-01,\n",
              "                                                         9.4133e-01, -3.4500e-01,  1.5887e-01, -9.9414e-01,  9.9524e-01,\n",
              "                                                        -9.8027e-01, -9.5119e-01, -9.2932e-01, -5.4739e-02, -8.4401e-01,\n",
              "                                                        -9.9807e-01, -1.7015e-01,  9.9941e-01,  7.0636e-01,  9.4815e-01,\n",
              "                                                        -1.6974e-01, -1.7527e-01, -8.8922e-01, -5.9811e-02, -9.9936e-01,\n",
              "                                                         9.2007e-01,  9.5592e-01, -9.1408e-01, -9.1644e-01,  9.5293e-01,\n",
              "                                                         8.9890e-01, -9.7215e-01, -9.8936e-01,  9.4242e-01,  3.0972e-01,\n",
              "                                                         9.2758e-01, -8.2622e-01, -3.3201e-02,  1.7098e-01,  1.3742e-01,\n",
              "                                                        -9.5930e-01, -8.2966e-01,  9.8505e-01, -9.9990e-01,  9.1397e-01,\n",
              "                                                         9.9883e-01,  9.9981e-01, -5.0678e-01,  2.7846e-01, -9.9423e-01,\n",
              "                                                         2.2278e-01, -4.4805e-01,  4.5658e-01, -9.9937e-01,  9.9868e-01,\n",
              "                                                        -9.9957e-01,  7.5750e-01, -8.5417e-01,  9.4782e-01,  9.5904e-01,\n",
              "                                                        -5.5548e-01, -9.9920e-01, -9.9859e-01,  8.0212e-01,  2.5710e-01,\n",
              "                                                         9.4823e-01,  4.4106e-01,  3.5408e-02, -8.7098e-01, -5.1631e-01,\n",
              "                                                         9.8472e-01, -9.2485e-01, -8.5797e-01, -9.9982e-01,  9.9783e-01,\n",
              "                                                         4.6552e-01, -9.9356e-01,  9.9829e-01, -9.9639e-01,  9.4897e-01,\n",
              "                                                         8.8045e-01,  6.6717e-01,  8.9250e-01, -9.9989e-01,  9.9961e-01,\n",
              "                                                        -9.9771e-01,  8.5554e-01, -9.9965e-01, -9.9990e-01,  9.9841e-01,\n",
              "                                                        -9.6599e-01, -8.8668e-01, -9.9808e-01, -9.9938e-01,  9.0888e-01,\n",
              "                                                        -5.3872e-02, -3.6070e-01,  9.5197e-01, -9.9881e-01, -9.9398e-01,\n",
              "                                                        -3.5568e-01, -9.7839e-01, -9.1364e-01,  9.9898e-01, -8.3859e-01,\n",
              "                                                         9.4392e-01, -3.6015e-01,  8.7438e-01,  5.7864e-01,  9.9923e-01,\n",
              "                                                         3.5037e-02, -9.0252e-01, -9.1225e-01, -9.7220e-01,  9.5525e-01,\n",
              "                                                        -8.4076e-01,  9.6486e-02,  9.0538e-01,  1.8820e-01, -8.7044e-01,\n",
              "                                                         1.8564e-01, -9.8948e-01,  6.2059e-01,  7.7048e-01,  9.8419e-01,\n",
              "                                                         9.7128e-01,  7.2791e-01, -2.4623e-01, -6.9740e-01, -4.1510e-01,\n",
              "                                                        -9.6647e-01,  4.2023e-01, -9.9703e-01,  9.4423e-01, -9.7672e-01,\n",
              "                                                        -1.6169e-01, -2.5738e-01,  6.5656e-03, -8.5697e-01,  9.9751e-01,\n",
              "                                                         9.9310e-01,  5.4130e-01, -1.2644e-01,  9.5288e-01, -9.1569e-01,\n",
              "                                                         9.0353e-01, -9.7191e-01,  2.2056e-01,  9.7740e-01, -5.2141e-01,\n",
              "                                                         9.2240e-01, -9.7886e-04,  8.3851e-02,  9.2990e-01, -9.7915e-01,\n",
              "                                                        -9.6249e-01, -5.2654e-01,  5.7186e-01, -2.1396e-01, -9.1610e-01,\n",
              "                                                        -8.2165e-02,  9.9713e-01, -5.6754e-01, -9.9841e-01,  9.5785e-01,\n",
              "                                                        -9.9697e-01,  2.2757e-02,  9.3265e-01, -6.1854e-01,  9.9935e-01,\n",
              "                                                        -9.1339e-01,  1.9538e-01,  2.3443e-01, -9.9843e-01, -9.9984e-01,\n",
              "                                                        -1.9310e-01,  5.1381e-02, -9.7614e-01,  9.9992e-01, -2.7237e-01,\n",
              "                                                         9.5085e-01, -9.9717e-01,  1.3411e-01,  9.9911e-01,  1.2105e-01,\n",
              "                                                         7.5110e-01, -9.1059e-01, -8.9012e-01, -9.7734e-01, -5.2351e-01,\n",
              "                                                        -1.5721e-01,  9.4909e-01, -8.9649e-01, -9.4281e-01, -9.3953e-01,\n",
              "                                                         9.9931e-01, -9.9009e-01, -8.3184e-01, -9.7041e-01,  7.4066e-01,\n",
              "                                                         9.2383e-01,  3.2850e-01,  8.5278e-02, -9.5874e-01,  9.8124e-01,\n",
              "                                                        -9.3666e-01,  9.8787e-01, -9.8298e-01, -9.8575e-01,  9.9864e-01,\n",
              "                                                         7.4289e-01, -9.9893e-01,  2.8596e-01, -1.1020e-01,  4.3229e-01,\n",
              "                                                         2.5131e-01,  9.2913e-01, -6.0190e-01, -1.8741e-02, -8.1253e-01,\n",
              "                                                         9.2107e-01, -9.6526e-01, -9.4245e-01, -2.8475e-01, -6.7595e-02,\n",
              "                                                         6.9409e-01,  9.7614e-01,  9.1326e-01,  9.9941e-01, -9.9847e-01,\n",
              "                                                         5.7175e-01, -8.8982e-02,  9.9510e-01,  3.8891e-02, -3.7319e-01,\n",
              "                                                         9.5328e-01,  9.9677e-01, -8.7734e-01,  9.6348e-01, -2.8657e-01,\n",
              "                                                         1.2884e-01,  4.8020e-01, -1.3139e-01,  9.9937e-01, -9.7720e-01,\n",
              "                                                        -1.9823e-01, -9.3161e-01, -9.9896e-01,  9.9908e-01,  1.3573e-01,\n",
              "                                                         9.6717e-01,  1.7948e-01,  8.5799e-01, -5.9515e-01,  9.8765e-01,\n",
              "                                                        -9.9035e-01, -7.9137e-01, -9.9962e-01,  1.4986e-02,  6.0266e-01,\n",
              "                                                        -9.6148e-01, -1.3529e-01,  8.9025e-01, -9.9678e-01, -9.4823e-01,\n",
              "                                                        -4.9686e-01, -9.9969e-01,  9.7316e-01, -9.9557e-01, -9.3093e-01,\n",
              "                                                        -9.3133e-01,  9.9977e-01, -8.1074e-02, -9.3798e-01,  9.2326e-01,\n",
              "                                                        -8.6809e-01,  9.8193e-01,  9.8385e-01, -9.5292e-01,  1.0273e-01,\n",
              "                                                        -1.3401e-01, -8.7999e-01, -9.9800e-01, -9.5786e-01, -9.2709e-01,\n",
              "                                                         9.2997e-01, -9.4443e-01, -6.5094e-01,  9.8726e-01,  9.3946e-01,\n",
              "                                                        -9.9347e-01, -9.8450e-01,  9.9888e-01,  4.0006e-01,  9.6862e-01,\n",
              "                                                        -2.5314e-01, -9.9879e-01, -9.9918e-01, -7.3838e-02,  2.0581e-01,\n",
              "                                                         9.7793e-01, -2.5827e-01, -6.4763e-01,  6.5461e-01, -5.5582e-01,\n",
              "                                                         7.9721e-01, -8.3256e-01, -4.7083e-01, -6.6073e-01,  4.0702e-02,\n",
              "                                                         9.9958e-01, -9.1134e-01,  9.6577e-01]], grad_fn=<TanhBackward>))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO9Xm8enyGtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a2b8fcd-c007-41b1-b864-b94a3d4aaabc"
      },
      "source": [
        "print(output[\"last_hidden_state\"].shape)\n",
        "print(output[\"pooler_output\"].shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 32, 768])\n",
            "torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwg_aOI-t-aC"
      },
      "source": [
        "last_hidden_state,pooled_output = bert_model(**enc)\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZ-Mjr_ezSQY"
      },
      "source": [
        "# Building Task specific Head over BERT "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsW0LXYOzRvR"
      },
      "source": [
        "class ToxicModel(nn.Module):\n",
        "  def __init__(self,n_classes):\n",
        "    super(ToxicModel,self).__init__()\n",
        "    self.bert  =BertModel.from_pretrained(PRETRAINED_MODEL_NAME)\n",
        "    self.drop = nn.Dropout(p=0.2)\n",
        "    self.output = nn.Linear(self.bert.config.hidden_size,n_classes)\n",
        "\n",
        "  \n",
        "  def forward(self,input_ids,attention_masks):\n",
        "    bert_output = self.bert(input_ids,attention_masks)\n",
        "    out  = self.drop(bert_output.pooler_output)\n",
        "    return self.output(out)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apgtiCD20WAw"
      },
      "source": [
        "N_CLASSES = df_train.toxic.nunique()\n",
        "model = ToxicModel(N_CLASSES)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpRqpfLx0u2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad05704-538c-48c5-f821-fdc1b36fbc93"
      },
      "source": [
        "model"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ToxicModel(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (drop): Dropout(p=0.2, inplace=False)\n",
              "  (output): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPF1bkcu0yM-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "434d6e23-bb76-4d19-b8c0-3feb20c5cc22"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "F.softmax(model(enc[\"input_ids\"],enc[\"attention_mask\"]),dim=1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4547, 0.5453]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLSBZwuixoNB",
        "outputId": "54ab4190-e02b-48c3-bcee-fdd7f7f988d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model(enc[\"input_ids\"],enc[\"attention_mask\"])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2608,  0.2428]], grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_KVRJYix2oL"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "EPOCHS = 2\n",
        "optimizer = AdamW(model.parameters(),lr = 2e-5, correct_bias = False)\n",
        "total_steps = len(train_data_loader)*EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 0,num_training_steps = total_steps)\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh52ovWizq0Q"
      },
      "source": [
        "def train_model(model,data_loader,loss_fn,optimizer,device,scheduler,n_examples):\n",
        "  model.train().to(device)\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  for data in data_loader:\n",
        "    input_ids = data[\"input_ids\"].to(device)\n",
        "    attention_mask = data[\"attention_mask\"].to(device)\n",
        "    targets = data[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(input_ids,attention_mask)\n",
        "    _,preds = torch.max(outputs,dim=1)\n",
        "    loss = loss_fn(outputs,targets)\n",
        "    correct_predictions+= torch.sum(preds ==targets)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm(model.parameters(),max_norm = 1)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses) "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6bBk8-41m8U"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(input_ids,attention_mask)\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiX5l0V41yjc",
        "outputId": "fa70c65b-cb53-4245-bfea-deb4e0b54d08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from collections import defaultdict\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_model(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.3295240240035447 accuracy 0.9342138246537569\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.2664181273229824 accuracy 0.9525600050134736\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.36754996516024796 accuracy 0.9349815128156921\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val   loss 0.4557389836501704 accuracy 0.9153349627122892\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJumKEh73Idh",
        "outputId": "e1b3435d-c66d-478e-e1ad-cf51692e5cdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XcVg5Nt5aYr",
        "outputId": "374f4f11-3a41-4f31-c9c2-8da0bf421631",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "\n",
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-383ad3ebd336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m test_acc, _ = eval_model(\n\u001b[1;32m      3\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_data_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-jiHdlJ5c4A"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDM8Yd9V5f56"
      },
      "source": [
        "\n",
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xlTj-I-s5h7u"
      },
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GB_siq95k54"
      },
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}